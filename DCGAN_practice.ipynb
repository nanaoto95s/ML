{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DCGAN_practice.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nanaoto95s/ML/blob/master/DCGAN_practice.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PiHF2_Jjrrg4",
        "colab_type": "code",
        "outputId": "42cfd98f-7ea3-4486-be2e-4ffe15d04981",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('./gdrive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at ./gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AgGCShDYh0qu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Activation, Reshape\n",
        "from keras.layers.normalization import BatchNormalization\n",
        "from keras.layers.convolutional import UpSampling2D, Conv2D\n",
        "from keras.layers.advanced_activations import LeakyReLU\n",
        "from keras.layers import Flatten, Dropout\n",
        "from keras.preprocessing.image import img_to_array, load_img\n",
        "from keras.optimizers import Adam\n",
        "import math\n",
        "import numpy as np\n",
        "import os\n",
        "from PIL import Image\n",
        "def generator_model():\n",
        "    model = Sequential()\n",
        "    model.add(Dense(input_dim=100, units=1024))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Activation('relu'))\n",
        "    model.add(Dense(32 * 32 * 128))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Activation('relu'))\n",
        "    model.add(Reshape((32, 32, 128), input_shape=(32 * 32 * 128,)))\n",
        "    model.add(UpSampling2D((2, 2)))\n",
        "    model.add(Conv2D(64, (5, 5), padding=\"same\"))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Activation('relu'))\n",
        "    model.add(UpSampling2D((2, 2)))\n",
        "    model.add(Conv2D(3, (5, 5), padding=\"same\"))\n",
        "    model.add(Activation('tanh'))\n",
        "    return model\n",
        "def discriminator_model():\n",
        "    model = Sequential()\n",
        "    model.add(Conv2D(64, (5,5), strides=(2, 2), input_shape=(128, 128, 3), padding=\"same\"))\n",
        "    model.add(LeakyReLU(0.2))\n",
        "    model.add(Conv2D(128, (5,5), strides=(2, 2)))\n",
        "    model.add(LeakyReLU(0.2))\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(256))\n",
        "    model.add(LeakyReLU(0.2))\n",
        "    model.add(Dropout(0.5))\n",
        "    model.add(Dense(1))\n",
        "    model.add(Activation('sigmoid'))\n",
        "    return model\n",
        "def combine_images(generated_images):\n",
        "    total = generated_images.shape[0]\n",
        "    cols = int(math.sqrt(total))\n",
        "    rows = math.ceil(float(total)/cols)\n",
        "    width, height, ch= generated_images.shape[1:]\n",
        "    output_shape = (\n",
        "        height * rows,\n",
        "        width * cols,\n",
        "        ch\n",
        "    )\n",
        "    combined_image = np.zeros(output_shape)\n",
        "\n",
        "    for index, image in enumerate(generated_images):\n",
        "        i = int(index/cols)\n",
        "        j = index % cols\n",
        "        combined_image[width*i:width*(i+1), height*j:height*(j+1)] = image[:, :, :]\n",
        "    return combined_image\n",
        "\n",
        "\n",
        "BATCH_SIZE = 32\n",
        "NUM_EPOCH = 1200\n",
        "GENERATED_IMAGE_PATH = './gdrive/My Drive/generated_images4/' # 生成画像の保存先\n",
        "TRAIN_IMAGE_PATH = './gdrive/My Drive/train_images/'\n",
        "\n",
        "def train():\n",
        "    # 訓練データ読み込み\n",
        "    img_list = os.listdir(TRAIN_IMAGE_PATH)\n",
        "    X_train = []\n",
        "    for img in img_list:\n",
        "        img = img_to_array(load_img(TRAIN_IMAGE_PATH+img, target_size=(128,128,3)))\n",
        "        # -1から1の範囲に正規化\n",
        "        img = (img.astype(np.float32) - 127.5)/127.5\n",
        "        X_train.append(img)\n",
        "    # 4Dテンソルに変換(データの個数, 128, 128, 3)\n",
        "    X_train = np.array(X_train)\n",
        "\n",
        "    # generatorとdiscriminatorを作成\n",
        "    discriminator = discriminator_model()\n",
        "    d_opt = Adam(lr=1e-5, beta_1=0.1)\n",
        "    discriminator.compile(loss='binary_crossentropy', optimizer=d_opt)\n",
        "    # discriminatorの重みを固定(dcganの中のみ)\n",
        "    discriminator.trainable = False\n",
        "    generator = generator_model()\n",
        "\n",
        "    dcgan = Sequential([generator, discriminator])\n",
        "    g_opt = Adam(lr=2e-4, beta_1=0.5)\n",
        "    dcgan.compile(loss='binary_crossentropy', optimizer=g_opt)\n",
        "\n",
        "    num_batches = int(X_train.shape[0] / BATCH_SIZE)\n",
        "    print('Number of batches:', num_batches)\n",
        "    for epoch in range(NUM_EPOCH):\n",
        "\n",
        "        for index in range(num_batches):\n",
        "            noise = np.array([np.random.uniform(-1, 1, 100) for _ in range(BATCH_SIZE)])\n",
        "            image_batch = X_train[index*BATCH_SIZE:(index+1)*BATCH_SIZE]\n",
        "            generated_images = generator.predict(noise, verbose=0, batch_size=BATCH_SIZE)\n",
        "\n",
        "            # 生成画像を出力\n",
        "            if (index+1) % (num_batches) == 0:\n",
        "                image = combine_images(generated_images)\n",
        "                image = image*127.5 + 127.5\n",
        "                if not os.path.exists(GENERATED_IMAGE_PATH):\n",
        "                    os.mkdir(GENERATED_IMAGE_PATH)\n",
        "                Image.fromarray(image.astype(np.uint8))\\\n",
        "                    .save(GENERATED_IMAGE_PATH+\"%04d_%04d.png\" % (epoch, index))\n",
        "\n",
        "            # discriminatorを更新\n",
        "            X = np.concatenate((image_batch, generated_images))\n",
        "            # 訓練データのラベルが1、生成画像のラベルが0になるよう学習する\n",
        "            y = [1]*BATCH_SIZE + [0]*BATCH_SIZE\n",
        "            d_loss = discriminator.train_on_batch(X, y)\n",
        "\n",
        "            # generator更新\n",
        "            noise = np.array([np.random.uniform(-1, 1, 100) for _ in range(BATCH_SIZE)])\n",
        "            # 生成画像をdiscriminatorにいれたときに\n",
        "            # 出力が1に近くなる(訓練画像と識別される確率が高くなる)ように学習する\n",
        "            g_loss = dcgan.train_on_batch(noise, [1]*BATCH_SIZE)\n",
        "\n",
        "            print(\"epoch: %d, batch: %d, g_loss: %f, d_loss: %f\" % (epoch, index, g_loss, d_loss))\n",
        "\n",
        "        generator.save_weights('generator.h5')\n",
        "        discriminator.save_weights('discriminator.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FZUGr-pEh2kd",
        "colab_type": "code",
        "outputId": "cc2c8fd5-cf6d-46cc-b497-455cb606fd81",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "train()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:148: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3733: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3657: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/nn_impl.py:183: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:2239: The name tf.image.resize_nearest_neighbor is deprecated. Please use tf.compat.v1.image.resize_nearest_neighbor instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:203: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:2041: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n",
            "\n",
            "Number of batches: 17\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/keras/engine/training.py:493: UserWarning: Discrepancy between trainable weights and collected trainable weights, did you set `model.trainable` without calling `model.compile` after ?\n",
            "  'Discrepancy between trainable weights and collected trainable'\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1020: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
            "\n",
            "epoch: 0, batch: 0, g_loss: 0.529374, d_loss: 0.721783\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/keras/engine/training.py:493: UserWarning: Discrepancy between trainable weights and collected trainable weights, did you set `model.trainable` without calling `model.compile` after ?\n",
            "  'Discrepancy between trainable weights and collected trainable'\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "epoch: 0, batch: 1, g_loss: 0.640991, d_loss: 0.635636\n",
            "epoch: 0, batch: 2, g_loss: 0.688177, d_loss: 0.605072\n",
            "epoch: 0, batch: 3, g_loss: 0.638295, d_loss: 0.629241\n",
            "epoch: 0, batch: 4, g_loss: 0.558168, d_loss: 0.680402\n",
            "epoch: 0, batch: 5, g_loss: 0.564658, d_loss: 0.723854\n",
            "epoch: 0, batch: 6, g_loss: 0.542046, d_loss: 0.660682\n",
            "epoch: 0, batch: 7, g_loss: 0.524637, d_loss: 0.564728\n",
            "epoch: 0, batch: 8, g_loss: 0.500010, d_loss: 0.574108\n",
            "epoch: 0, batch: 9, g_loss: 0.417706, d_loss: 0.602433\n",
            "epoch: 0, batch: 10, g_loss: 0.466307, d_loss: 0.675606\n",
            "epoch: 0, batch: 11, g_loss: 0.484073, d_loss: 0.664933\n",
            "epoch: 0, batch: 12, g_loss: 0.502712, d_loss: 0.696557\n",
            "epoch: 0, batch: 13, g_loss: 0.538681, d_loss: 0.649062\n",
            "epoch: 0, batch: 14, g_loss: 0.544749, d_loss: 0.623996\n",
            "epoch: 0, batch: 15, g_loss: 0.527702, d_loss: 0.707563\n",
            "epoch: 0, batch: 16, g_loss: 0.527952, d_loss: 0.619522\n",
            "epoch: 1, batch: 0, g_loss: 0.511814, d_loss: 0.577078\n",
            "epoch: 1, batch: 1, g_loss: 0.576769, d_loss: 0.536081\n",
            "epoch: 1, batch: 2, g_loss: 0.577215, d_loss: 0.608821\n",
            "epoch: 1, batch: 3, g_loss: 0.549830, d_loss: 0.646450\n",
            "epoch: 1, batch: 4, g_loss: 0.647883, d_loss: 0.602345\n",
            "epoch: 1, batch: 5, g_loss: 0.815490, d_loss: 0.690682\n",
            "epoch: 1, batch: 6, g_loss: 0.980797, d_loss: 0.562398\n",
            "epoch: 1, batch: 7, g_loss: 0.826005, d_loss: 0.617542\n",
            "epoch: 1, batch: 8, g_loss: 0.748338, d_loss: 0.603809\n",
            "epoch: 1, batch: 9, g_loss: 0.707540, d_loss: 0.567229\n",
            "epoch: 1, batch: 10, g_loss: 0.706088, d_loss: 0.595210\n",
            "epoch: 1, batch: 11, g_loss: 0.497914, d_loss: 0.564095\n",
            "epoch: 1, batch: 12, g_loss: 0.592013, d_loss: 0.533662\n",
            "epoch: 1, batch: 13, g_loss: 0.806807, d_loss: 0.504039\n",
            "epoch: 1, batch: 14, g_loss: 0.993995, d_loss: 0.529117\n",
            "epoch: 1, batch: 15, g_loss: 0.813055, d_loss: 0.604818\n",
            "epoch: 1, batch: 16, g_loss: 1.386702, d_loss: 0.533099\n",
            "epoch: 2, batch: 0, g_loss: 1.547528, d_loss: 0.428784\n",
            "epoch: 2, batch: 1, g_loss: 1.082992, d_loss: 0.560067\n",
            "epoch: 2, batch: 2, g_loss: 0.903741, d_loss: 0.738428\n",
            "epoch: 2, batch: 3, g_loss: 0.490387, d_loss: 0.704607\n",
            "epoch: 2, batch: 4, g_loss: 0.412807, d_loss: 0.465497\n",
            "epoch: 2, batch: 5, g_loss: 0.445535, d_loss: 0.621620\n",
            "epoch: 2, batch: 6, g_loss: 0.922503, d_loss: 0.555105\n",
            "epoch: 2, batch: 7, g_loss: 1.282113, d_loss: 0.653376\n",
            "epoch: 2, batch: 8, g_loss: 1.133538, d_loss: 0.588166\n",
            "epoch: 2, batch: 9, g_loss: 1.266131, d_loss: 0.543202\n",
            "epoch: 2, batch: 10, g_loss: 1.169062, d_loss: 0.513529\n",
            "epoch: 2, batch: 11, g_loss: 0.945303, d_loss: 0.535694\n",
            "epoch: 2, batch: 12, g_loss: 0.965426, d_loss: 0.521370\n",
            "epoch: 2, batch: 13, g_loss: 1.027528, d_loss: 0.457902\n",
            "epoch: 2, batch: 14, g_loss: 0.977807, d_loss: 0.736722\n",
            "epoch: 2, batch: 15, g_loss: 0.794574, d_loss: 0.779561\n",
            "epoch: 2, batch: 16, g_loss: 0.663175, d_loss: 0.604868\n",
            "epoch: 3, batch: 0, g_loss: 0.590639, d_loss: 0.500431\n",
            "epoch: 3, batch: 1, g_loss: 0.611709, d_loss: 0.457644\n",
            "epoch: 3, batch: 2, g_loss: 0.667552, d_loss: 0.528778\n",
            "epoch: 3, batch: 3, g_loss: 0.734026, d_loss: 0.593647\n",
            "epoch: 3, batch: 4, g_loss: 1.068278, d_loss: 0.529678\n",
            "epoch: 3, batch: 5, g_loss: 1.133597, d_loss: 0.553905\n",
            "epoch: 3, batch: 6, g_loss: 1.034075, d_loss: 0.527116\n",
            "epoch: 3, batch: 7, g_loss: 0.916105, d_loss: 0.568663\n",
            "epoch: 3, batch: 8, g_loss: 0.809177, d_loss: 0.490613\n",
            "epoch: 3, batch: 9, g_loss: 0.731735, d_loss: 0.522819\n",
            "epoch: 3, batch: 10, g_loss: 0.788541, d_loss: 0.466074\n",
            "epoch: 3, batch: 11, g_loss: 0.620957, d_loss: 0.621010\n",
            "epoch: 3, batch: 12, g_loss: 0.606356, d_loss: 0.634075\n",
            "epoch: 3, batch: 13, g_loss: 0.770913, d_loss: 0.544127\n",
            "epoch: 3, batch: 14, g_loss: 0.765008, d_loss: 0.576211\n",
            "epoch: 3, batch: 15, g_loss: 0.651171, d_loss: 0.518021\n",
            "epoch: 3, batch: 16, g_loss: 0.782736, d_loss: 0.524026\n",
            "epoch: 4, batch: 0, g_loss: 0.998503, d_loss: 0.467139\n",
            "epoch: 4, batch: 1, g_loss: 1.033464, d_loss: 0.486833\n",
            "epoch: 4, batch: 2, g_loss: 1.141379, d_loss: 0.499933\n",
            "epoch: 4, batch: 3, g_loss: 0.873244, d_loss: 0.639687\n",
            "epoch: 4, batch: 4, g_loss: 0.979733, d_loss: 0.499277\n",
            "epoch: 4, batch: 5, g_loss: 0.987341, d_loss: 0.560576\n",
            "epoch: 4, batch: 6, g_loss: 0.922775, d_loss: 0.620987\n",
            "epoch: 4, batch: 7, g_loss: 0.868820, d_loss: 0.665336\n",
            "epoch: 4, batch: 8, g_loss: 0.884819, d_loss: 0.610367\n",
            "epoch: 4, batch: 9, g_loss: 1.037440, d_loss: 0.656975\n",
            "epoch: 4, batch: 10, g_loss: 1.159892, d_loss: 0.499423\n",
            "epoch: 4, batch: 11, g_loss: 0.935443, d_loss: 0.726898\n",
            "epoch: 4, batch: 12, g_loss: 1.030932, d_loss: 0.632822\n",
            "epoch: 4, batch: 13, g_loss: 0.978340, d_loss: 0.511509\n",
            "epoch: 4, batch: 14, g_loss: 0.928733, d_loss: 0.641315\n",
            "epoch: 4, batch: 15, g_loss: 0.861102, d_loss: 0.705116\n",
            "epoch: 4, batch: 16, g_loss: 0.943758, d_loss: 0.910279\n",
            "epoch: 5, batch: 0, g_loss: 0.784332, d_loss: 0.620537\n",
            "epoch: 5, batch: 1, g_loss: 0.987408, d_loss: 0.729789\n",
            "epoch: 5, batch: 2, g_loss: 0.794345, d_loss: 0.666326\n",
            "epoch: 5, batch: 3, g_loss: 0.768818, d_loss: 0.707620\n",
            "epoch: 5, batch: 4, g_loss: 0.685361, d_loss: 0.593097\n",
            "epoch: 5, batch: 5, g_loss: 0.795325, d_loss: 0.586126\n",
            "epoch: 5, batch: 6, g_loss: 0.705606, d_loss: 0.569425\n",
            "epoch: 5, batch: 7, g_loss: 0.721069, d_loss: 0.662294\n",
            "epoch: 5, batch: 8, g_loss: 0.486977, d_loss: 0.547613\n",
            "epoch: 5, batch: 9, g_loss: 0.458952, d_loss: 0.623002\n",
            "epoch: 5, batch: 10, g_loss: 0.540878, d_loss: 0.610389\n",
            "epoch: 5, batch: 11, g_loss: 0.423830, d_loss: 0.692098\n",
            "epoch: 5, batch: 12, g_loss: 0.455411, d_loss: 0.641080\n",
            "epoch: 5, batch: 13, g_loss: 0.484707, d_loss: 0.689751\n",
            "epoch: 5, batch: 14, g_loss: 0.626523, d_loss: 0.662257\n",
            "epoch: 5, batch: 15, g_loss: 0.575100, d_loss: 0.637337\n",
            "epoch: 5, batch: 16, g_loss: 0.540602, d_loss: 0.630809\n",
            "epoch: 6, batch: 0, g_loss: 0.453655, d_loss: 0.561339\n",
            "epoch: 6, batch: 1, g_loss: 0.468623, d_loss: 0.526555\n",
            "epoch: 6, batch: 2, g_loss: 0.603131, d_loss: 0.547870\n",
            "epoch: 6, batch: 3, g_loss: 0.610087, d_loss: 0.502389\n",
            "epoch: 6, batch: 4, g_loss: 0.459122, d_loss: 0.487071\n",
            "epoch: 6, batch: 5, g_loss: 0.497586, d_loss: 0.556305\n",
            "epoch: 6, batch: 6, g_loss: 0.474374, d_loss: 0.553432\n",
            "epoch: 6, batch: 7, g_loss: 0.534535, d_loss: 0.627230\n",
            "epoch: 6, batch: 8, g_loss: 0.530431, d_loss: 0.643847\n",
            "epoch: 6, batch: 9, g_loss: 0.615416, d_loss: 0.720507\n",
            "epoch: 6, batch: 10, g_loss: 0.704924, d_loss: 0.647436\n",
            "epoch: 6, batch: 11, g_loss: 0.581400, d_loss: 0.762596\n",
            "epoch: 6, batch: 12, g_loss: 0.592121, d_loss: 0.696937\n",
            "epoch: 6, batch: 13, g_loss: 0.614422, d_loss: 0.620254\n",
            "epoch: 6, batch: 14, g_loss: 0.580492, d_loss: 0.625100\n",
            "epoch: 6, batch: 15, g_loss: 0.458812, d_loss: 0.632442\n",
            "epoch: 6, batch: 16, g_loss: 0.399433, d_loss: 0.536425\n",
            "epoch: 7, batch: 0, g_loss: 0.274662, d_loss: 0.473615\n",
            "epoch: 7, batch: 1, g_loss: 0.305846, d_loss: 0.573876\n",
            "epoch: 7, batch: 2, g_loss: 0.386151, d_loss: 0.560218\n",
            "epoch: 7, batch: 3, g_loss: 0.809909, d_loss: 0.658124\n",
            "epoch: 7, batch: 4, g_loss: 0.483970, d_loss: 0.711154\n",
            "epoch: 7, batch: 5, g_loss: 0.321035, d_loss: 0.734687\n",
            "epoch: 7, batch: 6, g_loss: 0.495892, d_loss: 0.699091\n",
            "epoch: 7, batch: 7, g_loss: 0.552886, d_loss: 0.541266\n",
            "epoch: 7, batch: 8, g_loss: 0.399668, d_loss: 0.488143\n",
            "epoch: 7, batch: 9, g_loss: 0.553298, d_loss: 0.513669\n",
            "epoch: 7, batch: 10, g_loss: 0.386138, d_loss: 0.409310\n",
            "epoch: 7, batch: 11, g_loss: 0.318470, d_loss: 0.352873\n",
            "epoch: 7, batch: 12, g_loss: 0.324898, d_loss: 0.407386\n",
            "epoch: 7, batch: 13, g_loss: 0.331910, d_loss: 0.390045\n",
            "epoch: 7, batch: 14, g_loss: 0.371394, d_loss: 0.517421\n",
            "epoch: 7, batch: 15, g_loss: 0.539039, d_loss: 0.544653\n",
            "epoch: 7, batch: 16, g_loss: 0.525411, d_loss: 0.897757\n",
            "epoch: 8, batch: 0, g_loss: 0.810060, d_loss: 0.997045\n",
            "epoch: 8, batch: 1, g_loss: 0.701971, d_loss: 0.898258\n",
            "epoch: 8, batch: 2, g_loss: 0.745438, d_loss: 0.812960\n",
            "epoch: 8, batch: 3, g_loss: 0.766033, d_loss: 0.812140\n",
            "epoch: 8, batch: 4, g_loss: 0.697657, d_loss: 0.623118\n",
            "epoch: 8, batch: 5, g_loss: 0.617624, d_loss: 0.575578\n",
            "epoch: 8, batch: 6, g_loss: 0.434697, d_loss: 0.493343\n",
            "epoch: 8, batch: 7, g_loss: 0.340505, d_loss: 0.436577\n",
            "epoch: 8, batch: 8, g_loss: 0.298188, d_loss: 0.448011\n",
            "epoch: 8, batch: 9, g_loss: 0.267143, d_loss: 0.429107\n",
            "epoch: 8, batch: 10, g_loss: 0.322570, d_loss: 0.497035\n",
            "epoch: 8, batch: 11, g_loss: 0.289090, d_loss: 0.483179\n",
            "epoch: 8, batch: 12, g_loss: 0.286302, d_loss: 0.583666\n",
            "epoch: 8, batch: 13, g_loss: 0.428368, d_loss: 0.629942\n",
            "epoch: 8, batch: 14, g_loss: 0.480634, d_loss: 0.579662\n",
            "epoch: 8, batch: 15, g_loss: 0.565694, d_loss: 0.794871\n",
            "epoch: 8, batch: 16, g_loss: 0.474829, d_loss: 0.754988\n",
            "epoch: 9, batch: 0, g_loss: 0.526610, d_loss: 0.725221\n",
            "epoch: 9, batch: 1, g_loss: 0.403580, d_loss: 0.580058\n",
            "epoch: 9, batch: 2, g_loss: 0.396465, d_loss: 0.488992\n",
            "epoch: 9, batch: 3, g_loss: 0.509087, d_loss: 0.570663\n",
            "epoch: 9, batch: 4, g_loss: 0.384137, d_loss: 0.464605\n",
            "epoch: 9, batch: 5, g_loss: 0.391933, d_loss: 0.469400\n",
            "epoch: 9, batch: 6, g_loss: 0.422695, d_loss: 0.445278\n",
            "epoch: 9, batch: 7, g_loss: 0.442445, d_loss: 0.596056\n",
            "epoch: 9, batch: 8, g_loss: 0.442685, d_loss: 0.478379\n",
            "epoch: 9, batch: 9, g_loss: 0.397330, d_loss: 0.714101\n",
            "epoch: 9, batch: 10, g_loss: 0.564727, d_loss: 0.649921\n",
            "epoch: 9, batch: 11, g_loss: 0.627160, d_loss: 0.658226\n",
            "epoch: 9, batch: 12, g_loss: 0.676177, d_loss: 0.734276\n",
            "epoch: 9, batch: 13, g_loss: 0.515976, d_loss: 0.744105\n",
            "epoch: 9, batch: 14, g_loss: 0.610448, d_loss: 0.688569\n",
            "epoch: 9, batch: 15, g_loss: 0.744669, d_loss: 0.736198\n",
            "epoch: 9, batch: 16, g_loss: 0.734864, d_loss: 0.699372\n",
            "epoch: 10, batch: 0, g_loss: 0.689634, d_loss: 0.652697\n",
            "epoch: 10, batch: 1, g_loss: 0.673968, d_loss: 0.599397\n",
            "epoch: 10, batch: 2, g_loss: 0.540118, d_loss: 0.620745\n",
            "epoch: 10, batch: 3, g_loss: 0.528369, d_loss: 0.694223\n",
            "epoch: 10, batch: 4, g_loss: 0.628559, d_loss: 0.676153\n",
            "epoch: 10, batch: 5, g_loss: 0.713685, d_loss: 0.660066\n",
            "epoch: 10, batch: 6, g_loss: 0.577547, d_loss: 0.575759\n",
            "epoch: 10, batch: 7, g_loss: 0.657200, d_loss: 0.602604\n",
            "epoch: 10, batch: 8, g_loss: 0.575108, d_loss: 0.590433\n",
            "epoch: 10, batch: 9, g_loss: 0.495236, d_loss: 0.591179\n",
            "epoch: 10, batch: 10, g_loss: 0.665694, d_loss: 0.621679\n",
            "epoch: 10, batch: 11, g_loss: 0.552236, d_loss: 0.514107\n",
            "epoch: 10, batch: 12, g_loss: 0.596183, d_loss: 0.558981\n",
            "epoch: 10, batch: 13, g_loss: 0.534496, d_loss: 0.678021\n",
            "epoch: 10, batch: 14, g_loss: 0.503358, d_loss: 0.574870\n",
            "epoch: 10, batch: 15, g_loss: 0.550384, d_loss: 0.631384\n",
            "epoch: 10, batch: 16, g_loss: 0.545141, d_loss: 0.667271\n",
            "epoch: 11, batch: 0, g_loss: 0.570850, d_loss: 0.645237\n",
            "epoch: 11, batch: 1, g_loss: 0.520607, d_loss: 0.486090\n",
            "epoch: 11, batch: 2, g_loss: 0.589433, d_loss: 0.619316\n",
            "epoch: 11, batch: 3, g_loss: 0.487075, d_loss: 0.684323\n",
            "epoch: 11, batch: 4, g_loss: 0.422995, d_loss: 0.563030\n",
            "epoch: 11, batch: 5, g_loss: 0.515205, d_loss: 0.597882\n",
            "epoch: 11, batch: 6, g_loss: 0.530412, d_loss: 0.586738\n",
            "epoch: 11, batch: 7, g_loss: 0.541556, d_loss: 0.654198\n",
            "epoch: 11, batch: 8, g_loss: 0.487676, d_loss: 0.650336\n",
            "epoch: 11, batch: 9, g_loss: 0.494813, d_loss: 0.614218\n",
            "epoch: 11, batch: 10, g_loss: 0.558967, d_loss: 0.581329\n",
            "epoch: 11, batch: 11, g_loss: 0.533890, d_loss: 0.570310\n",
            "epoch: 11, batch: 12, g_loss: 0.639131, d_loss: 0.600886\n",
            "epoch: 11, batch: 13, g_loss: 0.623243, d_loss: 0.585155\n",
            "epoch: 11, batch: 14, g_loss: 0.531053, d_loss: 0.508418\n",
            "epoch: 11, batch: 15, g_loss: 0.523970, d_loss: 0.609188\n",
            "epoch: 11, batch: 16, g_loss: 0.506812, d_loss: 0.489874\n",
            "epoch: 12, batch: 0, g_loss: 0.488459, d_loss: 0.584454\n",
            "epoch: 12, batch: 1, g_loss: 0.438053, d_loss: 0.550277\n",
            "epoch: 12, batch: 2, g_loss: 0.416830, d_loss: 0.570604\n",
            "epoch: 12, batch: 3, g_loss: 0.473873, d_loss: 0.668891\n",
            "epoch: 12, batch: 4, g_loss: 0.487404, d_loss: 0.695272\n",
            "epoch: 12, batch: 5, g_loss: 0.475837, d_loss: 0.730904\n",
            "epoch: 12, batch: 6, g_loss: 0.605423, d_loss: 0.697709\n",
            "epoch: 12, batch: 7, g_loss: 0.628217, d_loss: 0.616759\n",
            "epoch: 12, batch: 8, g_loss: 0.591076, d_loss: 0.526935\n",
            "epoch: 12, batch: 9, g_loss: 0.608022, d_loss: 0.568025\n",
            "epoch: 12, batch: 10, g_loss: 0.618559, d_loss: 0.563592\n",
            "epoch: 12, batch: 11, g_loss: 0.557994, d_loss: 0.574936\n",
            "epoch: 12, batch: 12, g_loss: 0.582852, d_loss: 0.699824\n",
            "epoch: 12, batch: 13, g_loss: 0.652549, d_loss: 0.695697\n",
            "epoch: 12, batch: 14, g_loss: 0.698636, d_loss: 0.739136\n",
            "epoch: 12, batch: 15, g_loss: 0.686314, d_loss: 0.654964\n",
            "epoch: 12, batch: 16, g_loss: 0.798321, d_loss: 0.554110\n",
            "epoch: 13, batch: 0, g_loss: 0.596827, d_loss: 0.468311\n",
            "epoch: 13, batch: 1, g_loss: 0.541156, d_loss: 0.449924\n",
            "epoch: 13, batch: 2, g_loss: 0.411799, d_loss: 0.516876\n",
            "epoch: 13, batch: 3, g_loss: 0.521531, d_loss: 0.698016\n",
            "epoch: 13, batch: 4, g_loss: 0.592415, d_loss: 0.642553\n",
            "epoch: 13, batch: 5, g_loss: 0.701522, d_loss: 0.751439\n",
            "epoch: 13, batch: 6, g_loss: 0.792639, d_loss: 0.715825\n",
            "epoch: 13, batch: 7, g_loss: 0.768602, d_loss: 0.683111\n",
            "epoch: 13, batch: 8, g_loss: 0.850720, d_loss: 0.624642\n",
            "epoch: 13, batch: 9, g_loss: 0.797633, d_loss: 0.643060\n",
            "epoch: 13, batch: 10, g_loss: 0.704001, d_loss: 0.604992\n",
            "epoch: 13, batch: 11, g_loss: 0.610434, d_loss: 0.614502\n",
            "epoch: 13, batch: 12, g_loss: 0.699401, d_loss: 0.760175\n",
            "epoch: 13, batch: 13, g_loss: 0.565568, d_loss: 0.650086\n",
            "epoch: 13, batch: 14, g_loss: 0.628868, d_loss: 0.646724\n",
            "epoch: 13, batch: 15, g_loss: 0.493034, d_loss: 0.611007\n",
            "epoch: 13, batch: 16, g_loss: 0.626837, d_loss: 0.654916\n",
            "epoch: 14, batch: 0, g_loss: 0.585438, d_loss: 0.557348\n",
            "epoch: 14, batch: 1, g_loss: 0.581411, d_loss: 0.586146\n",
            "epoch: 14, batch: 2, g_loss: 0.511367, d_loss: 0.561167\n",
            "epoch: 14, batch: 3, g_loss: 0.492320, d_loss: 0.650469\n",
            "epoch: 14, batch: 4, g_loss: 0.593693, d_loss: 0.567054\n",
            "epoch: 14, batch: 5, g_loss: 0.666046, d_loss: 0.625518\n",
            "epoch: 14, batch: 6, g_loss: 0.781716, d_loss: 0.580310\n",
            "epoch: 14, batch: 7, g_loss: 0.752287, d_loss: 0.632497\n",
            "epoch: 14, batch: 8, g_loss: 0.781203, d_loss: 0.600897\n",
            "epoch: 14, batch: 9, g_loss: 0.831400, d_loss: 0.670600\n",
            "epoch: 14, batch: 10, g_loss: 0.903391, d_loss: 0.661944\n",
            "epoch: 14, batch: 11, g_loss: 0.695346, d_loss: 0.726729\n",
            "epoch: 14, batch: 12, g_loss: 0.649321, d_loss: 0.721810\n",
            "epoch: 14, batch: 13, g_loss: 0.648152, d_loss: 0.714367\n",
            "epoch: 14, batch: 14, g_loss: 0.678463, d_loss: 0.655451\n",
            "epoch: 14, batch: 15, g_loss: 0.539814, d_loss: 0.612379\n",
            "epoch: 14, batch: 16, g_loss: 0.533623, d_loss: 0.620599\n",
            "epoch: 15, batch: 0, g_loss: 0.482294, d_loss: 0.646501\n",
            "epoch: 15, batch: 1, g_loss: 0.464477, d_loss: 0.721320\n",
            "epoch: 15, batch: 2, g_loss: 0.503967, d_loss: 0.710154\n",
            "epoch: 15, batch: 3, g_loss: 0.564234, d_loss: 0.733709\n",
            "epoch: 15, batch: 4, g_loss: 0.645476, d_loss: 0.636786\n",
            "epoch: 15, batch: 5, g_loss: 0.704751, d_loss: 0.598315\n",
            "epoch: 15, batch: 6, g_loss: 0.664247, d_loss: 0.585397\n",
            "epoch: 15, batch: 7, g_loss: 0.578116, d_loss: 0.595619\n",
            "epoch: 15, batch: 8, g_loss: 0.522136, d_loss: 0.540786\n",
            "epoch: 15, batch: 9, g_loss: 0.578359, d_loss: 0.714261\n",
            "epoch: 15, batch: 10, g_loss: 0.648489, d_loss: 0.639971\n",
            "epoch: 15, batch: 11, g_loss: 0.498462, d_loss: 0.687740\n",
            "epoch: 15, batch: 12, g_loss: 0.611760, d_loss: 0.643726\n",
            "epoch: 15, batch: 13, g_loss: 0.610663, d_loss: 0.570431\n",
            "epoch: 15, batch: 14, g_loss: 0.558649, d_loss: 0.565204\n",
            "epoch: 15, batch: 15, g_loss: 0.535556, d_loss: 0.611682\n",
            "epoch: 15, batch: 16, g_loss: 0.590773, d_loss: 0.667405\n",
            "epoch: 16, batch: 0, g_loss: 0.643397, d_loss: 0.680808\n",
            "epoch: 16, batch: 1, g_loss: 0.599867, d_loss: 0.683130\n",
            "epoch: 16, batch: 2, g_loss: 0.678353, d_loss: 0.631270\n",
            "epoch: 16, batch: 3, g_loss: 0.746717, d_loss: 0.665971\n",
            "epoch: 16, batch: 4, g_loss: 0.759871, d_loss: 0.576657\n",
            "epoch: 16, batch: 5, g_loss: 0.822744, d_loss: 0.564524\n",
            "epoch: 16, batch: 6, g_loss: 0.696486, d_loss: 0.527979\n",
            "epoch: 16, batch: 7, g_loss: 0.695056, d_loss: 0.653647\n",
            "epoch: 16, batch: 8, g_loss: 0.621032, d_loss: 0.621156\n",
            "epoch: 16, batch: 9, g_loss: 0.859527, d_loss: 0.809043\n",
            "epoch: 16, batch: 10, g_loss: 1.075395, d_loss: 0.674908\n",
            "epoch: 16, batch: 11, g_loss: 0.843121, d_loss: 0.661683\n",
            "epoch: 16, batch: 12, g_loss: 0.829622, d_loss: 0.640725\n",
            "epoch: 16, batch: 13, g_loss: 0.743526, d_loss: 0.686273\n",
            "epoch: 16, batch: 14, g_loss: 0.665322, d_loss: 0.598980\n",
            "epoch: 16, batch: 15, g_loss: 0.477082, d_loss: 0.660147\n",
            "epoch: 16, batch: 16, g_loss: 0.440777, d_loss: 0.628634\n",
            "epoch: 17, batch: 0, g_loss: 0.445586, d_loss: 0.753790\n",
            "epoch: 17, batch: 1, g_loss: 0.474166, d_loss: 0.686640\n",
            "epoch: 17, batch: 2, g_loss: 0.519990, d_loss: 0.597978\n",
            "epoch: 17, batch: 3, g_loss: 0.639934, d_loss: 0.644075\n",
            "epoch: 17, batch: 4, g_loss: 0.693230, d_loss: 0.570186\n",
            "epoch: 17, batch: 5, g_loss: 0.697856, d_loss: 0.567116\n",
            "epoch: 17, batch: 6, g_loss: 0.775692, d_loss: 0.585198\n",
            "epoch: 17, batch: 7, g_loss: 0.687374, d_loss: 0.619072\n",
            "epoch: 17, batch: 8, g_loss: 0.626706, d_loss: 0.613674\n",
            "epoch: 17, batch: 9, g_loss: 0.643833, d_loss: 0.594767\n",
            "epoch: 17, batch: 10, g_loss: 0.624129, d_loss: 0.577117\n",
            "epoch: 17, batch: 11, g_loss: 0.598452, d_loss: 0.783453\n",
            "epoch: 17, batch: 12, g_loss: 0.653992, d_loss: 0.659740\n",
            "epoch: 17, batch: 13, g_loss: 0.715298, d_loss: 0.644685\n",
            "epoch: 17, batch: 14, g_loss: 0.727934, d_loss: 0.630435\n",
            "epoch: 17, batch: 15, g_loss: 0.683921, d_loss: 0.634871\n",
            "epoch: 17, batch: 16, g_loss: 0.681296, d_loss: 0.633516\n",
            "epoch: 18, batch: 0, g_loss: 0.728375, d_loss: 0.620915\n",
            "epoch: 18, batch: 1, g_loss: 0.779263, d_loss: 0.642652\n",
            "epoch: 18, batch: 2, g_loss: 0.691559, d_loss: 0.623804\n",
            "epoch: 18, batch: 3, g_loss: 0.717823, d_loss: 0.693352\n",
            "epoch: 18, batch: 4, g_loss: 0.730955, d_loss: 0.615238\n",
            "epoch: 18, batch: 5, g_loss: 0.781553, d_loss: 0.604367\n",
            "epoch: 18, batch: 6, g_loss: 0.715364, d_loss: 0.622563\n",
            "epoch: 18, batch: 7, g_loss: 0.700519, d_loss: 0.658580\n",
            "epoch: 18, batch: 8, g_loss: 0.645506, d_loss: 0.629432\n",
            "epoch: 18, batch: 9, g_loss: 0.706514, d_loss: 0.664521\n",
            "epoch: 18, batch: 10, g_loss: 0.782143, d_loss: 0.572068\n",
            "epoch: 18, batch: 11, g_loss: 0.624060, d_loss: 0.709723\n",
            "epoch: 18, batch: 12, g_loss: 0.629913, d_loss: 0.593907\n",
            "epoch: 18, batch: 13, g_loss: 0.687075, d_loss: 0.616417\n",
            "epoch: 18, batch: 14, g_loss: 0.660364, d_loss: 0.707215\n",
            "epoch: 18, batch: 15, g_loss: 0.673445, d_loss: 0.705856\n",
            "epoch: 18, batch: 16, g_loss: 0.693855, d_loss: 0.703758\n",
            "epoch: 19, batch: 0, g_loss: 0.671936, d_loss: 0.699704\n",
            "epoch: 19, batch: 1, g_loss: 0.638530, d_loss: 0.661057\n",
            "epoch: 19, batch: 2, g_loss: 0.665755, d_loss: 0.664705\n",
            "epoch: 19, batch: 3, g_loss: 0.609691, d_loss: 0.650670\n",
            "epoch: 19, batch: 4, g_loss: 0.691946, d_loss: 0.657029\n",
            "epoch: 19, batch: 5, g_loss: 0.609280, d_loss: 0.601245\n",
            "epoch: 19, batch: 6, g_loss: 0.604384, d_loss: 0.644410\n",
            "epoch: 19, batch: 7, g_loss: 0.556918, d_loss: 0.703999\n",
            "epoch: 19, batch: 8, g_loss: 0.525573, d_loss: 0.632374\n",
            "epoch: 19, batch: 9, g_loss: 0.560917, d_loss: 0.671220\n",
            "epoch: 19, batch: 10, g_loss: 0.593893, d_loss: 0.618443\n",
            "epoch: 19, batch: 11, g_loss: 0.576753, d_loss: 0.592897\n",
            "epoch: 19, batch: 12, g_loss: 0.597346, d_loss: 0.571378\n",
            "epoch: 19, batch: 13, g_loss: 0.595620, d_loss: 0.568433\n",
            "epoch: 19, batch: 14, g_loss: 0.477929, d_loss: 0.545231\n",
            "epoch: 19, batch: 15, g_loss: 0.394536, d_loss: 0.596929\n",
            "epoch: 19, batch: 16, g_loss: 0.368300, d_loss: 0.594185\n",
            "epoch: 20, batch: 0, g_loss: 0.365581, d_loss: 0.558973\n",
            "epoch: 20, batch: 1, g_loss: 0.370775, d_loss: 0.571942\n",
            "epoch: 20, batch: 2, g_loss: 0.341267, d_loss: 0.552232\n",
            "epoch: 20, batch: 3, g_loss: 0.412260, d_loss: 0.634861\n",
            "epoch: 20, batch: 4, g_loss: 0.559129, d_loss: 0.586814\n",
            "epoch: 20, batch: 5, g_loss: 0.598543, d_loss: 0.553821\n",
            "epoch: 20, batch: 6, g_loss: 0.503386, d_loss: 0.546668\n",
            "epoch: 20, batch: 7, g_loss: 0.570808, d_loss: 0.593779\n",
            "epoch: 20, batch: 8, g_loss: 0.531600, d_loss: 0.505433\n",
            "epoch: 20, batch: 9, g_loss: 0.552950, d_loss: 0.628375\n",
            "epoch: 20, batch: 10, g_loss: 0.454910, d_loss: 0.604803\n",
            "epoch: 20, batch: 11, g_loss: 0.507250, d_loss: 0.626954\n",
            "epoch: 20, batch: 12, g_loss: 0.551097, d_loss: 0.680955\n",
            "epoch: 20, batch: 13, g_loss: 0.423615, d_loss: 0.619532\n",
            "epoch: 20, batch: 14, g_loss: 0.462642, d_loss: 0.578651\n",
            "epoch: 20, batch: 15, g_loss: 0.398370, d_loss: 0.594767\n",
            "epoch: 20, batch: 16, g_loss: 0.350901, d_loss: 0.556185\n",
            "epoch: 21, batch: 0, g_loss: 0.346782, d_loss: 0.489344\n",
            "epoch: 21, batch: 1, g_loss: 0.283071, d_loss: 0.498732\n",
            "epoch: 21, batch: 2, g_loss: 0.297749, d_loss: 0.476504\n",
            "epoch: 21, batch: 3, g_loss: 0.250637, d_loss: 0.574897\n",
            "epoch: 21, batch: 4, g_loss: 0.252934, d_loss: 0.534905\n",
            "epoch: 21, batch: 5, g_loss: 0.393677, d_loss: 0.590672\n",
            "epoch: 21, batch: 6, g_loss: 0.460581, d_loss: 0.563572\n",
            "epoch: 21, batch: 7, g_loss: 0.559960, d_loss: 0.598249\n",
            "epoch: 21, batch: 8, g_loss: 0.607473, d_loss: 0.537698\n",
            "epoch: 21, batch: 9, g_loss: 0.545992, d_loss: 0.535084\n",
            "epoch: 21, batch: 10, g_loss: 0.438808, d_loss: 0.550770\n",
            "epoch: 21, batch: 11, g_loss: 0.707074, d_loss: 0.529111\n",
            "epoch: 21, batch: 12, g_loss: 0.512002, d_loss: 0.515577\n",
            "epoch: 21, batch: 13, g_loss: 0.412099, d_loss: 0.538603\n",
            "epoch: 21, batch: 14, g_loss: 0.348167, d_loss: 0.519916\n",
            "epoch: 21, batch: 15, g_loss: 0.361858, d_loss: 0.635221\n",
            "epoch: 21, batch: 16, g_loss: 0.465980, d_loss: 0.618986\n",
            "epoch: 22, batch: 0, g_loss: 0.630110, d_loss: 0.595024\n",
            "epoch: 22, batch: 1, g_loss: 0.560852, d_loss: 0.672684\n",
            "epoch: 22, batch: 2, g_loss: 0.475462, d_loss: 0.577636\n",
            "epoch: 22, batch: 3, g_loss: 0.497159, d_loss: 0.658454\n",
            "epoch: 22, batch: 4, g_loss: 0.537971, d_loss: 0.541217\n",
            "epoch: 22, batch: 5, g_loss: 0.556771, d_loss: 0.528728\n",
            "epoch: 22, batch: 6, g_loss: 0.620783, d_loss: 0.553669\n",
            "epoch: 22, batch: 7, g_loss: 0.676588, d_loss: 0.616767\n",
            "epoch: 22, batch: 8, g_loss: 0.608485, d_loss: 0.586886\n",
            "epoch: 22, batch: 9, g_loss: 0.534806, d_loss: 0.698774\n",
            "epoch: 22, batch: 10, g_loss: 0.557013, d_loss: 0.604600\n",
            "epoch: 22, batch: 11, g_loss: 0.494123, d_loss: 0.716294\n",
            "epoch: 22, batch: 12, g_loss: 0.548693, d_loss: 0.654372\n",
            "epoch: 22, batch: 13, g_loss: 0.557057, d_loss: 0.553816\n",
            "epoch: 22, batch: 14, g_loss: 0.617326, d_loss: 0.565097\n",
            "epoch: 22, batch: 15, g_loss: 0.496846, d_loss: 0.591477\n",
            "epoch: 22, batch: 16, g_loss: 0.617638, d_loss: 0.626328\n",
            "epoch: 23, batch: 0, g_loss: 0.595499, d_loss: 0.632159\n",
            "epoch: 23, batch: 1, g_loss: 0.539780, d_loss: 0.643296\n",
            "epoch: 23, batch: 2, g_loss: 0.735954, d_loss: 0.626661\n",
            "epoch: 23, batch: 3, g_loss: 0.701972, d_loss: 0.564067\n",
            "epoch: 23, batch: 4, g_loss: 0.636270, d_loss: 0.624344\n",
            "epoch: 23, batch: 5, g_loss: 0.665201, d_loss: 0.657929\n",
            "epoch: 23, batch: 6, g_loss: 0.686996, d_loss: 0.608687\n",
            "epoch: 23, batch: 7, g_loss: 0.691388, d_loss: 0.592881\n",
            "epoch: 23, batch: 8, g_loss: 0.730584, d_loss: 0.680705\n",
            "epoch: 23, batch: 9, g_loss: 0.688237, d_loss: 0.594801\n",
            "epoch: 23, batch: 10, g_loss: 0.754967, d_loss: 0.614813\n",
            "epoch: 23, batch: 11, g_loss: 0.595241, d_loss: 0.665022\n",
            "epoch: 23, batch: 12, g_loss: 0.578529, d_loss: 0.561537\n",
            "epoch: 23, batch: 13, g_loss: 0.555247, d_loss: 0.612497\n",
            "epoch: 23, batch: 14, g_loss: 0.628194, d_loss: 0.602216\n",
            "epoch: 23, batch: 15, g_loss: 0.556024, d_loss: 0.532778\n",
            "epoch: 23, batch: 16, g_loss: 0.518355, d_loss: 0.587728\n",
            "epoch: 24, batch: 0, g_loss: 0.525889, d_loss: 0.597720\n",
            "epoch: 24, batch: 1, g_loss: 0.524317, d_loss: 0.633677\n",
            "epoch: 24, batch: 2, g_loss: 0.559097, d_loss: 0.576523\n",
            "epoch: 24, batch: 3, g_loss: 0.655029, d_loss: 0.614404\n",
            "epoch: 24, batch: 4, g_loss: 0.595893, d_loss: 0.601339\n",
            "epoch: 24, batch: 5, g_loss: 0.561023, d_loss: 0.601987\n",
            "epoch: 24, batch: 6, g_loss: 0.519709, d_loss: 0.583561\n",
            "epoch: 24, batch: 7, g_loss: 0.565627, d_loss: 0.627644\n",
            "epoch: 24, batch: 8, g_loss: 0.544859, d_loss: 0.624266\n",
            "epoch: 24, batch: 9, g_loss: 0.570155, d_loss: 0.639751\n",
            "epoch: 24, batch: 10, g_loss: 0.629266, d_loss: 0.630955\n",
            "epoch: 24, batch: 11, g_loss: 0.570356, d_loss: 0.684232\n",
            "epoch: 24, batch: 12, g_loss: 0.641661, d_loss: 0.606258\n",
            "epoch: 24, batch: 13, g_loss: 0.548616, d_loss: 0.555765\n",
            "epoch: 24, batch: 14, g_loss: 0.504725, d_loss: 0.550109\n",
            "epoch: 24, batch: 15, g_loss: 0.452615, d_loss: 0.564309\n",
            "epoch: 24, batch: 16, g_loss: 0.483890, d_loss: 0.636603\n",
            "epoch: 25, batch: 0, g_loss: 0.522123, d_loss: 0.649674\n",
            "epoch: 25, batch: 1, g_loss: 0.588760, d_loss: 0.654303\n",
            "epoch: 25, batch: 2, g_loss: 0.697781, d_loss: 0.612771\n",
            "epoch: 25, batch: 3, g_loss: 0.703320, d_loss: 0.611294\n",
            "epoch: 25, batch: 4, g_loss: 0.641065, d_loss: 0.593642\n",
            "epoch: 25, batch: 5, g_loss: 0.562941, d_loss: 0.540102\n",
            "epoch: 25, batch: 6, g_loss: 0.618024, d_loss: 0.633891\n",
            "epoch: 25, batch: 7, g_loss: 0.569001, d_loss: 0.631842\n",
            "epoch: 25, batch: 8, g_loss: 0.548910, d_loss: 0.630944\n",
            "epoch: 25, batch: 9, g_loss: 0.641102, d_loss: 0.701886\n",
            "epoch: 25, batch: 10, g_loss: 0.568674, d_loss: 0.562437\n",
            "epoch: 25, batch: 11, g_loss: 0.485698, d_loss: 0.640563\n",
            "epoch: 25, batch: 12, g_loss: 0.457185, d_loss: 0.552658\n",
            "epoch: 25, batch: 13, g_loss: 0.428547, d_loss: 0.493397\n",
            "epoch: 25, batch: 14, g_loss: 0.435069, d_loss: 0.573933\n",
            "epoch: 25, batch: 15, g_loss: 0.516400, d_loss: 0.643883\n",
            "epoch: 25, batch: 16, g_loss: 0.706180, d_loss: 0.625794\n",
            "epoch: 26, batch: 0, g_loss: 0.687692, d_loss: 0.646533\n",
            "epoch: 26, batch: 1, g_loss: 0.642225, d_loss: 0.666085\n",
            "epoch: 26, batch: 2, g_loss: 0.797549, d_loss: 0.678409\n",
            "epoch: 26, batch: 3, g_loss: 0.790384, d_loss: 0.656349\n",
            "epoch: 26, batch: 4, g_loss: 0.713747, d_loss: 0.613649\n",
            "epoch: 26, batch: 5, g_loss: 0.631965, d_loss: 0.612771\n",
            "epoch: 26, batch: 6, g_loss: 0.589862, d_loss: 0.590408\n",
            "epoch: 26, batch: 7, g_loss: 0.537639, d_loss: 0.646800\n",
            "epoch: 26, batch: 8, g_loss: 0.528911, d_loss: 0.617366\n",
            "epoch: 26, batch: 9, g_loss: 0.451925, d_loss: 0.670645\n",
            "epoch: 26, batch: 10, g_loss: 0.477352, d_loss: 0.685687\n",
            "epoch: 26, batch: 11, g_loss: 0.485076, d_loss: 0.692373\n",
            "epoch: 26, batch: 12, g_loss: 0.535387, d_loss: 0.642642\n",
            "epoch: 26, batch: 13, g_loss: 0.506578, d_loss: 0.540677\n",
            "epoch: 26, batch: 14, g_loss: 0.490426, d_loss: 0.563399\n",
            "epoch: 26, batch: 15, g_loss: 0.545548, d_loss: 0.714865\n",
            "epoch: 26, batch: 16, g_loss: 0.698511, d_loss: 0.614073\n",
            "epoch: 27, batch: 0, g_loss: 0.724260, d_loss: 0.687728\n",
            "epoch: 27, batch: 1, g_loss: 0.641063, d_loss: 0.686576\n",
            "epoch: 27, batch: 2, g_loss: 0.658665, d_loss: 0.617924\n",
            "epoch: 27, batch: 3, g_loss: 0.713089, d_loss: 0.586046\n",
            "epoch: 27, batch: 4, g_loss: 0.607858, d_loss: 0.593200\n",
            "epoch: 27, batch: 5, g_loss: 0.626019, d_loss: 0.634090\n",
            "epoch: 27, batch: 6, g_loss: 0.593715, d_loss: 0.613954\n",
            "epoch: 27, batch: 7, g_loss: 0.586352, d_loss: 0.640208\n",
            "epoch: 27, batch: 8, g_loss: 0.522991, d_loss: 0.679032\n",
            "epoch: 27, batch: 9, g_loss: 0.620775, d_loss: 0.729013\n",
            "epoch: 27, batch: 10, g_loss: 0.676455, d_loss: 0.641470\n",
            "epoch: 27, batch: 11, g_loss: 0.597804, d_loss: 0.649182\n",
            "epoch: 27, batch: 12, g_loss: 0.536826, d_loss: 0.610351\n",
            "epoch: 27, batch: 13, g_loss: 0.558644, d_loss: 0.614160\n",
            "epoch: 27, batch: 14, g_loss: 0.619455, d_loss: 0.665627\n",
            "epoch: 27, batch: 15, g_loss: 0.611348, d_loss: 0.696583\n",
            "epoch: 27, batch: 16, g_loss: 0.649106, d_loss: 0.652189\n",
            "epoch: 28, batch: 0, g_loss: 0.588989, d_loss: 0.686047\n",
            "epoch: 28, batch: 1, g_loss: 0.587320, d_loss: 0.680511\n",
            "epoch: 28, batch: 2, g_loss: 0.640297, d_loss: 0.630069\n",
            "epoch: 28, batch: 3, g_loss: 0.675820, d_loss: 0.624189\n",
            "epoch: 28, batch: 4, g_loss: 0.530620, d_loss: 0.646484\n",
            "epoch: 28, batch: 5, g_loss: 0.589484, d_loss: 0.680447\n",
            "epoch: 28, batch: 6, g_loss: 0.634500, d_loss: 0.665845\n",
            "epoch: 28, batch: 7, g_loss: 0.646072, d_loss: 0.714511\n",
            "epoch: 28, batch: 8, g_loss: 0.570970, d_loss: 0.624728\n",
            "epoch: 28, batch: 9, g_loss: 0.524016, d_loss: 0.592430\n",
            "epoch: 28, batch: 10, g_loss: 0.562447, d_loss: 0.595823\n",
            "epoch: 28, batch: 11, g_loss: 0.519317, d_loss: 0.669616\n",
            "epoch: 28, batch: 12, g_loss: 0.543733, d_loss: 0.630842\n",
            "epoch: 28, batch: 13, g_loss: 0.602815, d_loss: 0.631842\n",
            "epoch: 28, batch: 14, g_loss: 0.670557, d_loss: 0.675480\n",
            "epoch: 28, batch: 15, g_loss: 0.653551, d_loss: 0.654862\n",
            "epoch: 28, batch: 16, g_loss: 0.608561, d_loss: 0.663872\n",
            "epoch: 29, batch: 0, g_loss: 0.612527, d_loss: 0.679911\n",
            "epoch: 29, batch: 1, g_loss: 0.589322, d_loss: 0.642083\n",
            "epoch: 29, batch: 2, g_loss: 0.597533, d_loss: 0.610929\n",
            "epoch: 29, batch: 3, g_loss: 0.568593, d_loss: 0.621803\n",
            "epoch: 29, batch: 4, g_loss: 0.560311, d_loss: 0.648043\n",
            "epoch: 29, batch: 5, g_loss: 0.589927, d_loss: 0.641068\n",
            "epoch: 29, batch: 6, g_loss: 0.570695, d_loss: 0.620413\n",
            "epoch: 29, batch: 7, g_loss: 0.544047, d_loss: 0.626389\n",
            "epoch: 29, batch: 8, g_loss: 0.492429, d_loss: 0.671860\n",
            "epoch: 29, batch: 9, g_loss: 0.506629, d_loss: 0.622697\n",
            "epoch: 29, batch: 10, g_loss: 0.590190, d_loss: 0.658798\n",
            "epoch: 29, batch: 11, g_loss: 0.675300, d_loss: 0.714683\n",
            "epoch: 29, batch: 12, g_loss: 0.687023, d_loss: 0.652189\n",
            "epoch: 29, batch: 13, g_loss: 0.584077, d_loss: 0.670147\n",
            "epoch: 29, batch: 14, g_loss: 0.562508, d_loss: 0.673673\n",
            "epoch: 29, batch: 15, g_loss: 0.603788, d_loss: 0.662930\n",
            "epoch: 29, batch: 16, g_loss: 0.630124, d_loss: 0.637948\n",
            "epoch: 30, batch: 0, g_loss: 0.619141, d_loss: 0.650270\n",
            "epoch: 30, batch: 1, g_loss: 0.605809, d_loss: 0.634578\n",
            "epoch: 30, batch: 2, g_loss: 0.595875, d_loss: 0.640453\n",
            "epoch: 30, batch: 3, g_loss: 0.629714, d_loss: 0.706124\n",
            "epoch: 30, batch: 4, g_loss: 0.573317, d_loss: 0.681559\n",
            "epoch: 30, batch: 5, g_loss: 0.569051, d_loss: 0.659710\n",
            "epoch: 30, batch: 6, g_loss: 0.522578, d_loss: 0.637763\n",
            "epoch: 30, batch: 7, g_loss: 0.513321, d_loss: 0.622250\n",
            "epoch: 30, batch: 8, g_loss: 0.498915, d_loss: 0.656224\n",
            "epoch: 30, batch: 9, g_loss: 0.494032, d_loss: 0.644078\n",
            "epoch: 30, batch: 10, g_loss: 0.567105, d_loss: 0.656025\n",
            "epoch: 30, batch: 11, g_loss: 0.623791, d_loss: 0.678096\n",
            "epoch: 30, batch: 12, g_loss: 0.609237, d_loss: 0.677079\n",
            "epoch: 30, batch: 13, g_loss: 0.653776, d_loss: 0.645781\n",
            "epoch: 30, batch: 14, g_loss: 0.621359, d_loss: 0.645075\n",
            "epoch: 30, batch: 15, g_loss: 0.584436, d_loss: 0.674976\n",
            "epoch: 30, batch: 16, g_loss: 0.619049, d_loss: 0.672489\n",
            "epoch: 31, batch: 0, g_loss: 0.595848, d_loss: 0.658020\n",
            "epoch: 31, batch: 1, g_loss: 0.581699, d_loss: 0.688787\n",
            "epoch: 31, batch: 2, g_loss: 0.548684, d_loss: 0.595774\n",
            "epoch: 31, batch: 3, g_loss: 0.567605, d_loss: 0.616991\n",
            "epoch: 31, batch: 4, g_loss: 0.573173, d_loss: 0.696452\n",
            "epoch: 31, batch: 5, g_loss: 0.578760, d_loss: 0.680918\n",
            "epoch: 31, batch: 6, g_loss: 0.610694, d_loss: 0.627755\n",
            "epoch: 31, batch: 7, g_loss: 0.547609, d_loss: 0.550256\n",
            "epoch: 31, batch: 8, g_loss: 0.477032, d_loss: 0.610756\n",
            "epoch: 31, batch: 9, g_loss: 0.492968, d_loss: 0.657478\n",
            "epoch: 31, batch: 10, g_loss: 0.460571, d_loss: 0.637259\n",
            "epoch: 31, batch: 11, g_loss: 0.556327, d_loss: 0.748212\n",
            "epoch: 31, batch: 12, g_loss: 0.551834, d_loss: 0.653998\n",
            "epoch: 31, batch: 13, g_loss: 0.599147, d_loss: 0.660527\n",
            "epoch: 31, batch: 14, g_loss: 0.583392, d_loss: 0.626240\n",
            "epoch: 31, batch: 15, g_loss: 0.663262, d_loss: 0.698903\n",
            "epoch: 31, batch: 16, g_loss: 0.660028, d_loss: 0.661404\n",
            "epoch: 32, batch: 0, g_loss: 0.619288, d_loss: 0.718151\n",
            "epoch: 32, batch: 1, g_loss: 0.615716, d_loss: 0.679230\n",
            "epoch: 32, batch: 2, g_loss: 0.621334, d_loss: 0.649145\n",
            "epoch: 32, batch: 3, g_loss: 0.674230, d_loss: 0.645247\n",
            "epoch: 32, batch: 4, g_loss: 0.677846, d_loss: 0.618818\n",
            "epoch: 32, batch: 5, g_loss: 0.628815, d_loss: 0.608177\n",
            "epoch: 32, batch: 6, g_loss: 0.675582, d_loss: 0.730828\n",
            "epoch: 32, batch: 7, g_loss: 0.651387, d_loss: 0.667972\n",
            "epoch: 32, batch: 8, g_loss: 0.648272, d_loss: 0.661530\n",
            "epoch: 32, batch: 9, g_loss: 0.634493, d_loss: 0.675011\n",
            "epoch: 32, batch: 10, g_loss: 0.628518, d_loss: 0.629290\n",
            "epoch: 32, batch: 11, g_loss: 0.560909, d_loss: 0.658070\n",
            "epoch: 32, batch: 12, g_loss: 0.621535, d_loss: 0.697620\n",
            "epoch: 32, batch: 13, g_loss: 0.619611, d_loss: 0.636057\n",
            "epoch: 32, batch: 14, g_loss: 0.617289, d_loss: 0.641276\n",
            "epoch: 32, batch: 15, g_loss: 0.600753, d_loss: 0.666893\n",
            "epoch: 32, batch: 16, g_loss: 0.617846, d_loss: 0.657606\n",
            "epoch: 33, batch: 0, g_loss: 0.565747, d_loss: 0.662300\n",
            "epoch: 33, batch: 1, g_loss: 0.573892, d_loss: 0.640172\n",
            "epoch: 33, batch: 2, g_loss: 0.677589, d_loss: 0.692762\n",
            "epoch: 33, batch: 3, g_loss: 0.714063, d_loss: 0.622447\n",
            "epoch: 33, batch: 4, g_loss: 0.612141, d_loss: 0.724501\n",
            "epoch: 33, batch: 5, g_loss: 0.604902, d_loss: 0.641271\n",
            "epoch: 33, batch: 6, g_loss: 0.575887, d_loss: 0.617264\n",
            "epoch: 33, batch: 7, g_loss: 0.523172, d_loss: 0.614941\n",
            "epoch: 33, batch: 8, g_loss: 0.490257, d_loss: 0.633084\n",
            "epoch: 33, batch: 9, g_loss: 0.565878, d_loss: 0.719518\n",
            "epoch: 33, batch: 10, g_loss: 0.630525, d_loss: 0.646598\n",
            "epoch: 33, batch: 11, g_loss: 0.657032, d_loss: 0.632569\n",
            "epoch: 33, batch: 12, g_loss: 0.641291, d_loss: 0.680128\n",
            "epoch: 33, batch: 13, g_loss: 0.675425, d_loss: 0.651572\n",
            "epoch: 33, batch: 14, g_loss: 0.626680, d_loss: 0.672989\n",
            "epoch: 33, batch: 15, g_loss: 0.610538, d_loss: 0.639405\n",
            "epoch: 33, batch: 16, g_loss: 0.584353, d_loss: 0.681084\n",
            "epoch: 34, batch: 0, g_loss: 0.573984, d_loss: 0.644741\n",
            "epoch: 34, batch: 1, g_loss: 0.550004, d_loss: 0.639104\n",
            "epoch: 34, batch: 2, g_loss: 0.523484, d_loss: 0.643644\n",
            "epoch: 34, batch: 3, g_loss: 0.642459, d_loss: 0.688205\n",
            "epoch: 34, batch: 4, g_loss: 0.645396, d_loss: 0.620362\n",
            "epoch: 34, batch: 5, g_loss: 0.592126, d_loss: 0.612247\n",
            "epoch: 34, batch: 6, g_loss: 0.537614, d_loss: 0.615960\n",
            "epoch: 34, batch: 7, g_loss: 0.531962, d_loss: 0.623209\n",
            "epoch: 34, batch: 8, g_loss: 0.541706, d_loss: 0.684054\n",
            "epoch: 34, batch: 9, g_loss: 0.574633, d_loss: 0.659512\n",
            "epoch: 34, batch: 10, g_loss: 0.559404, d_loss: 0.614954\n",
            "epoch: 34, batch: 11, g_loss: 0.569084, d_loss: 0.625285\n",
            "epoch: 34, batch: 12, g_loss: 0.597355, d_loss: 0.621560\n",
            "epoch: 34, batch: 13, g_loss: 0.573754, d_loss: 0.574148\n",
            "epoch: 34, batch: 14, g_loss: 0.500194, d_loss: 0.576237\n",
            "epoch: 34, batch: 15, g_loss: 0.435014, d_loss: 0.647850\n",
            "epoch: 34, batch: 16, g_loss: 0.474590, d_loss: 0.641205\n",
            "epoch: 35, batch: 0, g_loss: 0.550111, d_loss: 0.655317\n",
            "epoch: 35, batch: 1, g_loss: 0.534659, d_loss: 0.630079\n",
            "epoch: 35, batch: 2, g_loss: 0.589894, d_loss: 0.619469\n",
            "epoch: 35, batch: 3, g_loss: 0.608549, d_loss: 0.666793\n",
            "epoch: 35, batch: 4, g_loss: 0.653584, d_loss: 0.677333\n",
            "epoch: 35, batch: 5, g_loss: 0.701595, d_loss: 0.652233\n",
            "epoch: 35, batch: 6, g_loss: 0.664857, d_loss: 0.643407\n",
            "epoch: 35, batch: 7, g_loss: 0.706777, d_loss: 0.646017\n",
            "epoch: 35, batch: 8, g_loss: 0.660082, d_loss: 0.628647\n",
            "epoch: 35, batch: 9, g_loss: 0.613100, d_loss: 0.700496\n",
            "epoch: 35, batch: 10, g_loss: 0.648079, d_loss: 0.642386\n",
            "epoch: 35, batch: 11, g_loss: 0.610035, d_loss: 0.640622\n",
            "epoch: 35, batch: 12, g_loss: 0.574741, d_loss: 0.648349\n",
            "epoch: 35, batch: 13, g_loss: 0.559288, d_loss: 0.676211\n",
            "epoch: 35, batch: 14, g_loss: 0.627247, d_loss: 0.636553\n",
            "epoch: 35, batch: 15, g_loss: 0.631181, d_loss: 0.590223\n",
            "epoch: 35, batch: 16, g_loss: 0.570557, d_loss: 0.631265\n",
            "epoch: 36, batch: 0, g_loss: 0.545989, d_loss: 0.598791\n",
            "epoch: 36, batch: 1, g_loss: 0.529113, d_loss: 0.592363\n",
            "epoch: 36, batch: 2, g_loss: 0.542443, d_loss: 0.602777\n",
            "epoch: 36, batch: 3, g_loss: 0.623834, d_loss: 0.690557\n",
            "epoch: 36, batch: 4, g_loss: 0.604443, d_loss: 0.702143\n",
            "epoch: 36, batch: 5, g_loss: 0.620556, d_loss: 0.659539\n",
            "epoch: 36, batch: 6, g_loss: 0.627473, d_loss: 0.648062\n",
            "epoch: 36, batch: 7, g_loss: 0.583314, d_loss: 0.665033\n",
            "epoch: 36, batch: 8, g_loss: 0.612209, d_loss: 0.641663\n",
            "epoch: 36, batch: 9, g_loss: 0.614340, d_loss: 0.661087\n",
            "epoch: 36, batch: 10, g_loss: 0.599163, d_loss: 0.631467\n",
            "epoch: 36, batch: 11, g_loss: 0.622828, d_loss: 0.660850\n",
            "epoch: 36, batch: 12, g_loss: 0.588121, d_loss: 0.674139\n",
            "epoch: 36, batch: 13, g_loss: 0.554489, d_loss: 0.635274\n",
            "epoch: 36, batch: 14, g_loss: 0.546698, d_loss: 0.615252\n",
            "epoch: 36, batch: 15, g_loss: 0.529512, d_loss: 0.639189\n",
            "epoch: 36, batch: 16, g_loss: 0.550531, d_loss: 0.653197\n",
            "epoch: 37, batch: 0, g_loss: 0.565428, d_loss: 0.642523\n",
            "epoch: 37, batch: 1, g_loss: 0.552365, d_loss: 0.657962\n",
            "epoch: 37, batch: 2, g_loss: 0.581485, d_loss: 0.637841\n",
            "epoch: 37, batch: 3, g_loss: 0.581283, d_loss: 0.673251\n",
            "epoch: 37, batch: 4, g_loss: 0.528112, d_loss: 0.607592\n",
            "epoch: 37, batch: 5, g_loss: 0.546815, d_loss: 0.609719\n",
            "epoch: 37, batch: 6, g_loss: 0.558773, d_loss: 0.617013\n",
            "epoch: 37, batch: 7, g_loss: 0.539928, d_loss: 0.646142\n",
            "epoch: 37, batch: 8, g_loss: 0.522956, d_loss: 0.631680\n",
            "epoch: 37, batch: 9, g_loss: 0.585090, d_loss: 0.669037\n",
            "epoch: 37, batch: 10, g_loss: 0.577099, d_loss: 0.597528\n",
            "epoch: 37, batch: 11, g_loss: 0.523682, d_loss: 0.650923\n",
            "epoch: 37, batch: 12, g_loss: 0.555831, d_loss: 0.627038\n",
            "epoch: 37, batch: 13, g_loss: 0.593895, d_loss: 0.607334\n",
            "epoch: 37, batch: 14, g_loss: 0.610473, d_loss: 0.649432\n",
            "epoch: 37, batch: 15, g_loss: 0.564397, d_loss: 0.640807\n",
            "epoch: 37, batch: 16, g_loss: 0.544006, d_loss: 0.657166\n",
            "epoch: 38, batch: 0, g_loss: 0.565367, d_loss: 0.680477\n",
            "epoch: 38, batch: 1, g_loss: 0.558056, d_loss: 0.603837\n",
            "epoch: 38, batch: 2, g_loss: 0.564710, d_loss: 0.641496\n",
            "epoch: 38, batch: 3, g_loss: 0.569692, d_loss: 0.646805\n",
            "epoch: 38, batch: 4, g_loss: 0.565797, d_loss: 0.627639\n",
            "epoch: 38, batch: 5, g_loss: 0.587377, d_loss: 0.647343\n",
            "epoch: 38, batch: 6, g_loss: 0.592931, d_loss: 0.612212\n",
            "epoch: 38, batch: 7, g_loss: 0.555281, d_loss: 0.659790\n",
            "epoch: 38, batch: 8, g_loss: 0.510469, d_loss: 0.622687\n",
            "epoch: 38, batch: 9, g_loss: 0.559678, d_loss: 0.627805\n",
            "epoch: 38, batch: 10, g_loss: 0.521220, d_loss: 0.621831\n",
            "epoch: 38, batch: 11, g_loss: 0.522600, d_loss: 0.612441\n",
            "epoch: 38, batch: 12, g_loss: 0.548751, d_loss: 0.606700\n",
            "epoch: 38, batch: 13, g_loss: 0.537240, d_loss: 0.606408\n",
            "epoch: 38, batch: 14, g_loss: 0.597510, d_loss: 0.648358\n",
            "epoch: 38, batch: 15, g_loss: 0.574091, d_loss: 0.579887\n",
            "epoch: 38, batch: 16, g_loss: 0.579185, d_loss: 0.624659\n",
            "epoch: 39, batch: 0, g_loss: 0.567390, d_loss: 0.649792\n",
            "epoch: 39, batch: 1, g_loss: 0.529523, d_loss: 0.641349\n",
            "epoch: 39, batch: 2, g_loss: 0.560084, d_loss: 0.587825\n",
            "epoch: 39, batch: 3, g_loss: 0.558638, d_loss: 0.660987\n",
            "epoch: 39, batch: 4, g_loss: 0.549807, d_loss: 0.594711\n",
            "epoch: 39, batch: 5, g_loss: 0.543811, d_loss: 0.632886\n",
            "epoch: 39, batch: 6, g_loss: 0.555842, d_loss: 0.613292\n",
            "epoch: 39, batch: 7, g_loss: 0.570330, d_loss: 0.668213\n",
            "epoch: 39, batch: 8, g_loss: 0.507719, d_loss: 0.638577\n",
            "epoch: 39, batch: 9, g_loss: 0.563146, d_loss: 0.621037\n",
            "epoch: 39, batch: 10, g_loss: 0.573149, d_loss: 0.639946\n",
            "epoch: 39, batch: 11, g_loss: 0.520456, d_loss: 0.632976\n",
            "epoch: 39, batch: 12, g_loss: 0.529067, d_loss: 0.653519\n",
            "epoch: 39, batch: 13, g_loss: 0.544898, d_loss: 0.634277\n",
            "epoch: 39, batch: 14, g_loss: 0.572674, d_loss: 0.633258\n",
            "epoch: 39, batch: 15, g_loss: 0.525840, d_loss: 0.603537\n",
            "epoch: 39, batch: 16, g_loss: 0.609263, d_loss: 0.650918\n",
            "epoch: 40, batch: 0, g_loss: 0.561773, d_loss: 0.653055\n",
            "epoch: 40, batch: 1, g_loss: 0.520474, d_loss: 0.632808\n",
            "epoch: 40, batch: 2, g_loss: 0.564623, d_loss: 0.625971\n",
            "epoch: 40, batch: 3, g_loss: 0.541212, d_loss: 0.640419\n",
            "epoch: 40, batch: 4, g_loss: 0.549354, d_loss: 0.619494\n",
            "epoch: 40, batch: 5, g_loss: 0.548221, d_loss: 0.608871\n",
            "epoch: 40, batch: 6, g_loss: 0.526670, d_loss: 0.580119\n",
            "epoch: 40, batch: 7, g_loss: 0.493917, d_loss: 0.659829\n",
            "epoch: 40, batch: 8, g_loss: 0.491571, d_loss: 0.660224\n",
            "epoch: 40, batch: 9, g_loss: 0.569925, d_loss: 0.653898\n",
            "epoch: 40, batch: 10, g_loss: 0.559842, d_loss: 0.650506\n",
            "epoch: 40, batch: 11, g_loss: 0.635971, d_loss: 0.648759\n",
            "epoch: 40, batch: 12, g_loss: 0.621664, d_loss: 0.665915\n",
            "epoch: 40, batch: 13, g_loss: 0.610609, d_loss: 0.652546\n",
            "epoch: 40, batch: 14, g_loss: 0.639198, d_loss: 0.646256\n",
            "epoch: 40, batch: 15, g_loss: 0.587953, d_loss: 0.624484\n",
            "epoch: 40, batch: 16, g_loss: 0.601822, d_loss: 0.665120\n",
            "epoch: 41, batch: 0, g_loss: 0.549143, d_loss: 0.635808\n",
            "epoch: 41, batch: 1, g_loss: 0.517235, d_loss: 0.629119\n",
            "epoch: 41, batch: 2, g_loss: 0.590222, d_loss: 0.634432\n",
            "epoch: 41, batch: 3, g_loss: 0.573869, d_loss: 0.649943\n",
            "epoch: 41, batch: 4, g_loss: 0.582480, d_loss: 0.591505\n",
            "epoch: 41, batch: 5, g_loss: 0.551219, d_loss: 0.603364\n",
            "epoch: 41, batch: 6, g_loss: 0.581266, d_loss: 0.651448\n",
            "epoch: 41, batch: 7, g_loss: 0.606067, d_loss: 0.638716\n",
            "epoch: 41, batch: 8, g_loss: 0.615177, d_loss: 0.676469\n",
            "epoch: 41, batch: 9, g_loss: 0.605388, d_loss: 0.678565\n",
            "epoch: 41, batch: 10, g_loss: 0.599934, d_loss: 0.629983\n",
            "epoch: 41, batch: 11, g_loss: 0.574784, d_loss: 0.662024\n",
            "epoch: 41, batch: 12, g_loss: 0.533943, d_loss: 0.630648\n",
            "epoch: 41, batch: 13, g_loss: 0.518007, d_loss: 0.628907\n",
            "epoch: 41, batch: 14, g_loss: 0.540388, d_loss: 0.622486\n",
            "epoch: 41, batch: 15, g_loss: 0.542913, d_loss: 0.616818\n",
            "epoch: 41, batch: 16, g_loss: 0.562271, d_loss: 0.662646\n",
            "epoch: 42, batch: 0, g_loss: 0.551413, d_loss: 0.625637\n",
            "epoch: 42, batch: 1, g_loss: 0.589331, d_loss: 0.637597\n",
            "epoch: 42, batch: 2, g_loss: 0.626247, d_loss: 0.619188\n",
            "epoch: 42, batch: 3, g_loss: 0.649113, d_loss: 0.659942\n",
            "epoch: 42, batch: 4, g_loss: 0.593112, d_loss: 0.621402\n",
            "epoch: 42, batch: 5, g_loss: 0.574959, d_loss: 0.607570\n",
            "epoch: 42, batch: 6, g_loss: 0.567339, d_loss: 0.628707\n",
            "epoch: 42, batch: 7, g_loss: 0.572460, d_loss: 0.629643\n",
            "epoch: 42, batch: 8, g_loss: 0.594120, d_loss: 0.670572\n",
            "epoch: 42, batch: 9, g_loss: 0.576386, d_loss: 0.656380\n",
            "epoch: 42, batch: 10, g_loss: 0.558931, d_loss: 0.649763\n",
            "epoch: 42, batch: 11, g_loss: 0.560483, d_loss: 0.651909\n",
            "epoch: 42, batch: 12, g_loss: 0.568191, d_loss: 0.635826\n",
            "epoch: 42, batch: 13, g_loss: 0.561151, d_loss: 0.632979\n",
            "epoch: 42, batch: 14, g_loss: 0.609022, d_loss: 0.589824\n",
            "epoch: 42, batch: 15, g_loss: 0.609111, d_loss: 0.601989\n",
            "epoch: 42, batch: 16, g_loss: 0.593199, d_loss: 0.648000\n",
            "epoch: 43, batch: 0, g_loss: 0.579556, d_loss: 0.683330\n",
            "epoch: 43, batch: 1, g_loss: 0.589990, d_loss: 0.619793\n",
            "epoch: 43, batch: 2, g_loss: 0.573814, d_loss: 0.630051\n",
            "epoch: 43, batch: 3, g_loss: 0.560173, d_loss: 0.630899\n",
            "epoch: 43, batch: 4, g_loss: 0.567797, d_loss: 0.663091\n",
            "epoch: 43, batch: 5, g_loss: 0.518333, d_loss: 0.551177\n",
            "epoch: 43, batch: 6, g_loss: 0.549867, d_loss: 0.571788\n",
            "epoch: 43, batch: 7, g_loss: 0.479262, d_loss: 0.594494\n",
            "epoch: 43, batch: 8, g_loss: 0.426378, d_loss: 0.599488\n",
            "epoch: 43, batch: 9, g_loss: 0.473952, d_loss: 0.676155\n",
            "epoch: 43, batch: 10, g_loss: 0.460049, d_loss: 0.555952\n",
            "epoch: 43, batch: 11, g_loss: 0.498326, d_loss: 0.670305\n",
            "epoch: 43, batch: 12, g_loss: 0.551863, d_loss: 0.658024\n",
            "epoch: 43, batch: 13, g_loss: 0.614520, d_loss: 0.654974\n",
            "epoch: 43, batch: 14, g_loss: 0.623711, d_loss: 0.591764\n",
            "epoch: 43, batch: 15, g_loss: 0.629580, d_loss: 0.626521\n",
            "epoch: 43, batch: 16, g_loss: 0.577601, d_loss: 0.610330\n",
            "epoch: 44, batch: 0, g_loss: 0.609455, d_loss: 0.633731\n",
            "epoch: 44, batch: 1, g_loss: 0.633727, d_loss: 0.631742\n",
            "epoch: 44, batch: 2, g_loss: 0.592923, d_loss: 0.558686\n",
            "epoch: 44, batch: 3, g_loss: 0.590956, d_loss: 0.593762\n",
            "epoch: 44, batch: 4, g_loss: 0.557685, d_loss: 0.574557\n",
            "epoch: 44, batch: 5, g_loss: 0.520239, d_loss: 0.604922\n",
            "epoch: 44, batch: 6, g_loss: 0.545945, d_loss: 0.608315\n",
            "epoch: 44, batch: 7, g_loss: 0.541514, d_loss: 0.615419\n",
            "epoch: 44, batch: 8, g_loss: 0.586165, d_loss: 0.654606\n",
            "epoch: 44, batch: 9, g_loss: 0.535924, d_loss: 0.642119\n",
            "epoch: 44, batch: 10, g_loss: 0.511658, d_loss: 0.624346\n",
            "epoch: 44, batch: 11, g_loss: 0.548308, d_loss: 0.612508\n",
            "epoch: 44, batch: 12, g_loss: 0.558232, d_loss: 0.626456\n",
            "epoch: 44, batch: 13, g_loss: 0.588850, d_loss: 0.620092\n",
            "epoch: 44, batch: 14, g_loss: 0.590828, d_loss: 0.648825\n",
            "epoch: 44, batch: 15, g_loss: 0.541000, d_loss: 0.618683\n",
            "epoch: 44, batch: 16, g_loss: 0.583092, d_loss: 0.633653\n",
            "epoch: 45, batch: 0, g_loss: 0.581862, d_loss: 0.596292\n",
            "epoch: 45, batch: 1, g_loss: 0.585201, d_loss: 0.597480\n",
            "epoch: 45, batch: 2, g_loss: 0.559072, d_loss: 0.551735\n",
            "epoch: 45, batch: 3, g_loss: 0.595608, d_loss: 0.650608\n",
            "epoch: 45, batch: 4, g_loss: 0.588105, d_loss: 0.568336\n",
            "epoch: 45, batch: 5, g_loss: 0.543485, d_loss: 0.615972\n",
            "epoch: 45, batch: 6, g_loss: 0.541317, d_loss: 0.594155\n",
            "epoch: 45, batch: 7, g_loss: 0.543396, d_loss: 0.587749\n",
            "epoch: 45, batch: 8, g_loss: 0.538355, d_loss: 0.635779\n",
            "epoch: 45, batch: 9, g_loss: 0.527585, d_loss: 0.618087\n",
            "epoch: 45, batch: 10, g_loss: 0.572207, d_loss: 0.610165\n",
            "epoch: 45, batch: 11, g_loss: 0.572245, d_loss: 0.683979\n",
            "epoch: 45, batch: 12, g_loss: 0.628725, d_loss: 0.628505\n",
            "epoch: 45, batch: 13, g_loss: 0.607264, d_loss: 0.618335\n",
            "epoch: 45, batch: 14, g_loss: 0.584064, d_loss: 0.598810\n",
            "epoch: 45, batch: 15, g_loss: 0.552939, d_loss: 0.604925\n",
            "epoch: 45, batch: 16, g_loss: 0.581149, d_loss: 0.644111\n",
            "epoch: 46, batch: 0, g_loss: 0.629344, d_loss: 0.625590\n",
            "epoch: 46, batch: 1, g_loss: 0.579552, d_loss: 0.576994\n",
            "epoch: 46, batch: 2, g_loss: 0.480250, d_loss: 0.589311\n",
            "epoch: 46, batch: 3, g_loss: 0.446294, d_loss: 0.612972\n",
            "epoch: 46, batch: 4, g_loss: 0.484277, d_loss: 0.593317\n",
            "epoch: 46, batch: 5, g_loss: 0.540753, d_loss: 0.534184\n",
            "epoch: 46, batch: 6, g_loss: 0.561556, d_loss: 0.598787\n",
            "epoch: 46, batch: 7, g_loss: 0.512077, d_loss: 0.543883\n",
            "epoch: 46, batch: 8, g_loss: 0.535026, d_loss: 0.623607\n",
            "epoch: 46, batch: 9, g_loss: 0.643631, d_loss: 0.638964\n",
            "epoch: 46, batch: 10, g_loss: 0.576530, d_loss: 0.602286\n",
            "epoch: 46, batch: 11, g_loss: 0.538685, d_loss: 0.619040\n",
            "epoch: 46, batch: 12, g_loss: 0.558416, d_loss: 0.568909\n",
            "epoch: 46, batch: 13, g_loss: 0.534042, d_loss: 0.587901\n",
            "epoch: 46, batch: 14, g_loss: 0.529260, d_loss: 0.590717\n",
            "epoch: 46, batch: 15, g_loss: 0.476219, d_loss: 0.534841\n",
            "epoch: 46, batch: 16, g_loss: 0.479637, d_loss: 0.593564\n",
            "epoch: 47, batch: 0, g_loss: 0.461619, d_loss: 0.554048\n",
            "epoch: 47, batch: 1, g_loss: 0.478565, d_loss: 0.566309\n",
            "epoch: 47, batch: 2, g_loss: 0.502247, d_loss: 0.602023\n",
            "epoch: 47, batch: 3, g_loss: 0.554538, d_loss: 0.615862\n",
            "epoch: 47, batch: 4, g_loss: 0.576263, d_loss: 0.557784\n",
            "epoch: 47, batch: 5, g_loss: 0.585721, d_loss: 0.636239\n",
            "epoch: 47, batch: 6, g_loss: 0.519474, d_loss: 0.595064\n",
            "epoch: 47, batch: 7, g_loss: 0.501513, d_loss: 0.582298\n",
            "epoch: 47, batch: 8, g_loss: 0.515812, d_loss: 0.623084\n",
            "epoch: 47, batch: 9, g_loss: 0.536664, d_loss: 0.603004\n",
            "epoch: 47, batch: 10, g_loss: 0.603716, d_loss: 0.653111\n",
            "epoch: 47, batch: 11, g_loss: 0.476283, d_loss: 0.607268\n",
            "epoch: 47, batch: 12, g_loss: 0.476356, d_loss: 0.568136\n",
            "epoch: 47, batch: 13, g_loss: 0.492642, d_loss: 0.566427\n",
            "epoch: 47, batch: 14, g_loss: 0.540994, d_loss: 0.566021\n",
            "epoch: 47, batch: 15, g_loss: 0.517688, d_loss: 0.547622\n",
            "epoch: 47, batch: 16, g_loss: 0.523604, d_loss: 0.587418\n",
            "epoch: 48, batch: 0, g_loss: 0.483719, d_loss: 0.605666\n",
            "epoch: 48, batch: 1, g_loss: 0.494228, d_loss: 0.527910\n",
            "epoch: 48, batch: 2, g_loss: 0.525925, d_loss: 0.550740\n",
            "epoch: 48, batch: 3, g_loss: 0.506973, d_loss: 0.641935\n",
            "epoch: 48, batch: 4, g_loss: 0.489948, d_loss: 0.576627\n",
            "epoch: 48, batch: 5, g_loss: 0.502920, d_loss: 0.588789\n",
            "epoch: 48, batch: 6, g_loss: 0.489625, d_loss: 0.541270\n",
            "epoch: 48, batch: 7, g_loss: 0.469966, d_loss: 0.554698\n",
            "epoch: 48, batch: 8, g_loss: 0.420765, d_loss: 0.556960\n",
            "epoch: 48, batch: 9, g_loss: 0.430903, d_loss: 0.511237\n",
            "epoch: 48, batch: 10, g_loss: 0.395829, d_loss: 0.502134\n",
            "epoch: 48, batch: 11, g_loss: 0.395661, d_loss: 0.571867\n",
            "epoch: 48, batch: 12, g_loss: 0.435472, d_loss: 0.550372\n",
            "epoch: 48, batch: 13, g_loss: 0.490734, d_loss: 0.507485\n",
            "epoch: 48, batch: 14, g_loss: 0.559905, d_loss: 0.602098\n",
            "epoch: 48, batch: 15, g_loss: 0.478776, d_loss: 0.586247\n",
            "epoch: 48, batch: 16, g_loss: 0.448171, d_loss: 0.559828\n",
            "epoch: 49, batch: 0, g_loss: 0.396611, d_loss: 0.540065\n",
            "epoch: 49, batch: 1, g_loss: 0.503430, d_loss: 0.575983\n",
            "epoch: 49, batch: 2, g_loss: 0.493234, d_loss: 0.558469\n",
            "epoch: 49, batch: 3, g_loss: 0.448857, d_loss: 0.623129\n",
            "epoch: 49, batch: 4, g_loss: 0.456651, d_loss: 0.572276\n",
            "epoch: 49, batch: 5, g_loss: 0.443236, d_loss: 0.537533\n",
            "epoch: 49, batch: 6, g_loss: 0.475840, d_loss: 0.547251\n",
            "epoch: 49, batch: 7, g_loss: 0.447377, d_loss: 0.582761\n",
            "epoch: 49, batch: 8, g_loss: 0.487076, d_loss: 0.571439\n",
            "epoch: 49, batch: 9, g_loss: 0.431801, d_loss: 0.488770\n",
            "epoch: 49, batch: 10, g_loss: 0.409865, d_loss: 0.502036\n",
            "epoch: 49, batch: 11, g_loss: 0.356660, d_loss: 0.563135\n",
            "epoch: 49, batch: 12, g_loss: 0.347180, d_loss: 0.522035\n",
            "epoch: 49, batch: 13, g_loss: 0.377994, d_loss: 0.530475\n",
            "epoch: 49, batch: 14, g_loss: 0.414489, d_loss: 0.587915\n",
            "epoch: 49, batch: 15, g_loss: 0.436227, d_loss: 0.532617\n",
            "epoch: 49, batch: 16, g_loss: 0.432053, d_loss: 0.628469\n",
            "epoch: 50, batch: 0, g_loss: 0.433935, d_loss: 0.535994\n",
            "epoch: 50, batch: 1, g_loss: 0.579314, d_loss: 0.621499\n",
            "epoch: 50, batch: 2, g_loss: 0.558726, d_loss: 0.600157\n",
            "epoch: 50, batch: 3, g_loss: 0.596831, d_loss: 0.537548\n",
            "epoch: 50, batch: 4, g_loss: 0.447365, d_loss: 0.589064\n",
            "epoch: 50, batch: 5, g_loss: 0.447562, d_loss: 0.657218\n",
            "epoch: 50, batch: 6, g_loss: 0.445324, d_loss: 0.556866\n",
            "epoch: 50, batch: 7, g_loss: 0.416194, d_loss: 0.564198\n",
            "epoch: 50, batch: 8, g_loss: 0.414435, d_loss: 0.527314\n",
            "epoch: 50, batch: 9, g_loss: 0.412199, d_loss: 0.575196\n",
            "epoch: 50, batch: 10, g_loss: 0.419418, d_loss: 0.513200\n",
            "epoch: 50, batch: 11, g_loss: 0.347428, d_loss: 0.610744\n",
            "epoch: 50, batch: 12, g_loss: 0.369627, d_loss: 0.546448\n",
            "epoch: 50, batch: 13, g_loss: 0.449532, d_loss: 0.596127\n",
            "epoch: 50, batch: 14, g_loss: 0.473310, d_loss: 0.548619\n",
            "epoch: 50, batch: 15, g_loss: 0.596531, d_loss: 0.629455\n",
            "epoch: 50, batch: 16, g_loss: 0.623095, d_loss: 0.570617\n",
            "epoch: 51, batch: 0, g_loss: 0.497822, d_loss: 0.632759\n",
            "epoch: 51, batch: 1, g_loss: 0.460181, d_loss: 0.586973\n",
            "epoch: 51, batch: 2, g_loss: 0.454713, d_loss: 0.539463\n",
            "epoch: 51, batch: 3, g_loss: 0.482423, d_loss: 0.596610\n",
            "epoch: 51, batch: 4, g_loss: 0.522863, d_loss: 0.570317\n",
            "epoch: 51, batch: 5, g_loss: 0.524004, d_loss: 0.596310\n",
            "epoch: 51, batch: 6, g_loss: 0.458953, d_loss: 0.591149\n",
            "epoch: 51, batch: 7, g_loss: 0.493070, d_loss: 0.585356\n",
            "epoch: 51, batch: 8, g_loss: 0.469404, d_loss: 0.572277\n",
            "epoch: 51, batch: 9, g_loss: 0.451335, d_loss: 0.577370\n",
            "epoch: 51, batch: 10, g_loss: 0.542815, d_loss: 0.513518\n",
            "epoch: 51, batch: 11, g_loss: 0.430223, d_loss: 0.620218\n",
            "epoch: 51, batch: 12, g_loss: 0.470200, d_loss: 0.585294\n",
            "epoch: 51, batch: 13, g_loss: 0.451911, d_loss: 0.539664\n",
            "epoch: 51, batch: 14, g_loss: 0.482629, d_loss: 0.582619\n",
            "epoch: 51, batch: 15, g_loss: 0.645905, d_loss: 0.642590\n",
            "epoch: 51, batch: 16, g_loss: 0.627561, d_loss: 0.642808\n",
            "epoch: 52, batch: 0, g_loss: 0.593237, d_loss: 0.608722\n",
            "epoch: 52, batch: 1, g_loss: 0.496471, d_loss: 0.585963\n",
            "epoch: 52, batch: 2, g_loss: 0.526677, d_loss: 0.575225\n",
            "epoch: 52, batch: 3, g_loss: 0.598914, d_loss: 0.620045\n",
            "epoch: 52, batch: 4, g_loss: 0.571873, d_loss: 0.568347\n",
            "epoch: 52, batch: 5, g_loss: 0.521913, d_loss: 0.593837\n",
            "epoch: 52, batch: 6, g_loss: 0.488222, d_loss: 0.572519\n",
            "epoch: 52, batch: 7, g_loss: 0.509916, d_loss: 0.621741\n",
            "epoch: 52, batch: 8, g_loss: 0.577097, d_loss: 0.637634\n",
            "epoch: 52, batch: 9, g_loss: 0.580839, d_loss: 0.640449\n",
            "epoch: 52, batch: 10, g_loss: 0.636679, d_loss: 0.639176\n",
            "epoch: 52, batch: 11, g_loss: 0.646054, d_loss: 0.644984\n",
            "epoch: 52, batch: 12, g_loss: 0.642557, d_loss: 0.602841\n",
            "epoch: 52, batch: 13, g_loss: 0.612820, d_loss: 0.584963\n",
            "epoch: 52, batch: 14, g_loss: 0.629407, d_loss: 0.590868\n",
            "epoch: 52, batch: 15, g_loss: 0.544948, d_loss: 0.628323\n",
            "epoch: 52, batch: 16, g_loss: 0.576578, d_loss: 0.653698\n",
            "epoch: 53, batch: 0, g_loss: 0.647188, d_loss: 0.580699\n",
            "epoch: 53, batch: 1, g_loss: 0.591018, d_loss: 0.633176\n",
            "epoch: 53, batch: 2, g_loss: 0.594616, d_loss: 0.573846\n",
            "epoch: 53, batch: 3, g_loss: 0.573942, d_loss: 0.575213\n",
            "epoch: 53, batch: 4, g_loss: 0.652213, d_loss: 0.631481\n",
            "epoch: 53, batch: 5, g_loss: 0.610338, d_loss: 0.601312\n",
            "epoch: 53, batch: 6, g_loss: 0.563405, d_loss: 0.627241\n",
            "epoch: 53, batch: 7, g_loss: 0.542466, d_loss: 0.626413\n",
            "epoch: 53, batch: 8, g_loss: 0.554593, d_loss: 0.654550\n",
            "epoch: 53, batch: 9, g_loss: 0.548553, d_loss: 0.610641\n",
            "epoch: 53, batch: 10, g_loss: 0.521686, d_loss: 0.595096\n",
            "epoch: 53, batch: 11, g_loss: 0.516351, d_loss: 0.644367\n",
            "epoch: 53, batch: 12, g_loss: 0.583969, d_loss: 0.599055\n",
            "epoch: 53, batch: 13, g_loss: 0.555320, d_loss: 0.613188\n",
            "epoch: 53, batch: 14, g_loss: 0.554322, d_loss: 0.604146\n",
            "epoch: 53, batch: 15, g_loss: 0.523199, d_loss: 0.609228\n",
            "epoch: 53, batch: 16, g_loss: 0.547428, d_loss: 0.644092\n",
            "epoch: 54, batch: 0, g_loss: 0.519568, d_loss: 0.613444\n",
            "epoch: 54, batch: 1, g_loss: 0.544016, d_loss: 0.603886\n",
            "epoch: 54, batch: 2, g_loss: 0.565956, d_loss: 0.585904\n",
            "epoch: 54, batch: 3, g_loss: 0.553512, d_loss: 0.612723\n",
            "epoch: 54, batch: 4, g_loss: 0.533187, d_loss: 0.585214\n",
            "epoch: 54, batch: 5, g_loss: 0.608127, d_loss: 0.605156\n",
            "epoch: 54, batch: 6, g_loss: 0.600354, d_loss: 0.621136\n",
            "epoch: 54, batch: 7, g_loss: 0.544931, d_loss: 0.567775\n",
            "epoch: 54, batch: 8, g_loss: 0.467457, d_loss: 0.573892\n",
            "epoch: 54, batch: 9, g_loss: 0.462294, d_loss: 0.577761\n",
            "epoch: 54, batch: 10, g_loss: 0.418469, d_loss: 0.542134\n",
            "epoch: 54, batch: 11, g_loss: 0.446848, d_loss: 0.607451\n",
            "epoch: 54, batch: 12, g_loss: 0.491189, d_loss: 0.588004\n",
            "epoch: 54, batch: 13, g_loss: 0.589355, d_loss: 0.637222\n",
            "epoch: 54, batch: 14, g_loss: 0.622378, d_loss: 0.555951\n",
            "epoch: 54, batch: 15, g_loss: 0.610879, d_loss: 0.647292\n",
            "epoch: 54, batch: 16, g_loss: 0.669172, d_loss: 0.647041\n",
            "epoch: 55, batch: 0, g_loss: 0.645554, d_loss: 0.620717\n",
            "epoch: 55, batch: 1, g_loss: 0.703786, d_loss: 0.590341\n",
            "epoch: 55, batch: 2, g_loss: 0.787787, d_loss: 0.599323\n",
            "epoch: 55, batch: 3, g_loss: 0.856395, d_loss: 0.548128\n",
            "epoch: 55, batch: 4, g_loss: 0.601711, d_loss: 0.561252\n",
            "epoch: 55, batch: 5, g_loss: 0.534529, d_loss: 0.602243\n",
            "epoch: 55, batch: 6, g_loss: 0.531907, d_loss: 0.598601\n",
            "epoch: 55, batch: 7, g_loss: 0.512252, d_loss: 0.599068\n",
            "epoch: 55, batch: 8, g_loss: 0.630419, d_loss: 0.622476\n",
            "epoch: 55, batch: 9, g_loss: 0.702612, d_loss: 0.637925\n",
            "epoch: 55, batch: 10, g_loss: 0.707649, d_loss: 0.604096\n",
            "epoch: 55, batch: 11, g_loss: 0.563846, d_loss: 0.649822\n",
            "epoch: 55, batch: 12, g_loss: 0.615992, d_loss: 0.587908\n",
            "epoch: 55, batch: 13, g_loss: 0.555033, d_loss: 0.545768\n",
            "epoch: 55, batch: 14, g_loss: 0.544109, d_loss: 0.584566\n",
            "epoch: 55, batch: 15, g_loss: 0.596856, d_loss: 0.605965\n",
            "epoch: 55, batch: 16, g_loss: 0.750935, d_loss: 0.598700\n",
            "epoch: 56, batch: 0, g_loss: 0.583696, d_loss: 0.614146\n",
            "epoch: 56, batch: 1, g_loss: 0.594896, d_loss: 0.656381\n",
            "epoch: 56, batch: 2, g_loss: 0.595051, d_loss: 0.547729\n",
            "epoch: 56, batch: 3, g_loss: 0.645404, d_loss: 0.608862\n",
            "epoch: 56, batch: 4, g_loss: 0.585350, d_loss: 0.593520\n",
            "epoch: 56, batch: 5, g_loss: 0.540666, d_loss: 0.643774\n",
            "epoch: 56, batch: 6, g_loss: 0.617956, d_loss: 0.635584\n",
            "epoch: 56, batch: 7, g_loss: 0.552638, d_loss: 0.579159\n",
            "epoch: 56, batch: 8, g_loss: 0.504160, d_loss: 0.596568\n",
            "epoch: 56, batch: 9, g_loss: 0.540992, d_loss: 0.662485\n",
            "epoch: 56, batch: 10, g_loss: 0.603378, d_loss: 0.628955\n",
            "epoch: 56, batch: 11, g_loss: 0.666138, d_loss: 0.610559\n",
            "epoch: 56, batch: 12, g_loss: 0.676232, d_loss: 0.648237\n",
            "epoch: 56, batch: 13, g_loss: 0.663953, d_loss: 0.610135\n",
            "epoch: 56, batch: 14, g_loss: 0.636280, d_loss: 0.599621\n",
            "epoch: 56, batch: 15, g_loss: 0.613826, d_loss: 0.571228\n",
            "epoch: 56, batch: 16, g_loss: 0.584238, d_loss: 0.639274\n",
            "epoch: 57, batch: 0, g_loss: 0.553019, d_loss: 0.584454\n",
            "epoch: 57, batch: 1, g_loss: 0.525362, d_loss: 0.559303\n",
            "epoch: 57, batch: 2, g_loss: 0.603474, d_loss: 0.561829\n",
            "epoch: 57, batch: 3, g_loss: 0.536741, d_loss: 0.651607\n",
            "epoch: 57, batch: 4, g_loss: 0.656139, d_loss: 0.650731\n",
            "epoch: 57, batch: 5, g_loss: 0.622876, d_loss: 0.578489\n",
            "epoch: 57, batch: 6, g_loss: 0.597047, d_loss: 0.577652\n",
            "epoch: 57, batch: 7, g_loss: 0.661981, d_loss: 0.621308\n",
            "epoch: 57, batch: 8, g_loss: 0.627864, d_loss: 0.599882\n",
            "epoch: 57, batch: 9, g_loss: 0.592256, d_loss: 0.629732\n",
            "epoch: 57, batch: 10, g_loss: 0.589459, d_loss: 0.640318\n",
            "epoch: 57, batch: 11, g_loss: 0.521531, d_loss: 0.571536\n",
            "epoch: 57, batch: 12, g_loss: 0.570818, d_loss: 0.540914\n",
            "epoch: 57, batch: 13, g_loss: 0.506768, d_loss: 0.557740\n",
            "epoch: 57, batch: 14, g_loss: 0.540290, d_loss: 0.636175\n",
            "epoch: 57, batch: 15, g_loss: 0.549021, d_loss: 0.588442\n",
            "epoch: 57, batch: 16, g_loss: 0.588116, d_loss: 0.610251\n",
            "epoch: 58, batch: 0, g_loss: 0.574125, d_loss: 0.603499\n",
            "epoch: 58, batch: 1, g_loss: 0.591703, d_loss: 0.607230\n",
            "epoch: 58, batch: 2, g_loss: 0.742233, d_loss: 0.612038\n",
            "epoch: 58, batch: 3, g_loss: 0.649152, d_loss: 0.546237\n",
            "epoch: 58, batch: 4, g_loss: 0.600515, d_loss: 0.633847\n",
            "epoch: 58, batch: 5, g_loss: 0.617362, d_loss: 0.623004\n",
            "epoch: 58, batch: 6, g_loss: 0.581791, d_loss: 0.556428\n",
            "epoch: 58, batch: 7, g_loss: 0.526813, d_loss: 0.652512\n",
            "epoch: 58, batch: 8, g_loss: 0.557886, d_loss: 0.597317\n",
            "epoch: 58, batch: 9, g_loss: 0.581872, d_loss: 0.590229\n",
            "epoch: 58, batch: 10, g_loss: 0.620128, d_loss: 0.641990\n",
            "epoch: 58, batch: 11, g_loss: 0.589997, d_loss: 0.637130\n",
            "epoch: 58, batch: 12, g_loss: 0.625123, d_loss: 0.641420\n",
            "epoch: 58, batch: 13, g_loss: 0.585139, d_loss: 0.544029\n",
            "epoch: 58, batch: 14, g_loss: 0.605001, d_loss: 0.599545\n",
            "epoch: 58, batch: 15, g_loss: 0.545445, d_loss: 0.603646\n",
            "epoch: 58, batch: 16, g_loss: 0.598790, d_loss: 0.604388\n",
            "epoch: 59, batch: 0, g_loss: 0.593099, d_loss: 0.586017\n",
            "epoch: 59, batch: 1, g_loss: 0.584120, d_loss: 0.558458\n",
            "epoch: 59, batch: 2, g_loss: 0.679574, d_loss: 0.563448\n",
            "epoch: 59, batch: 3, g_loss: 0.676259, d_loss: 0.572071\n",
            "epoch: 59, batch: 4, g_loss: 0.692460, d_loss: 0.699036\n",
            "epoch: 59, batch: 5, g_loss: 0.702785, d_loss: 0.603695\n",
            "epoch: 59, batch: 6, g_loss: 0.585524, d_loss: 0.581087\n",
            "epoch: 59, batch: 7, g_loss: 0.554850, d_loss: 0.579241\n",
            "epoch: 59, batch: 8, g_loss: 0.488943, d_loss: 0.589899\n",
            "epoch: 59, batch: 9, g_loss: 0.493570, d_loss: 0.595409\n",
            "epoch: 59, batch: 10, g_loss: 0.523962, d_loss: 0.584319\n",
            "epoch: 59, batch: 11, g_loss: 0.587139, d_loss: 0.628809\n",
            "epoch: 59, batch: 12, g_loss: 0.624648, d_loss: 0.590161\n",
            "epoch: 59, batch: 13, g_loss: 0.618031, d_loss: 0.613415\n",
            "epoch: 59, batch: 14, g_loss: 0.659201, d_loss: 0.576612\n",
            "epoch: 59, batch: 15, g_loss: 0.595362, d_loss: 0.613339\n",
            "epoch: 59, batch: 16, g_loss: 0.654116, d_loss: 0.613074\n",
            "epoch: 60, batch: 0, g_loss: 0.612017, d_loss: 0.581055\n",
            "epoch: 60, batch: 1, g_loss: 0.617565, d_loss: 0.608368\n",
            "epoch: 60, batch: 2, g_loss: 0.599198, d_loss: 0.575111\n",
            "epoch: 60, batch: 3, g_loss: 0.652789, d_loss: 0.573526\n",
            "epoch: 60, batch: 4, g_loss: 0.576019, d_loss: 0.601061\n",
            "epoch: 60, batch: 5, g_loss: 0.551991, d_loss: 0.600257\n",
            "epoch: 60, batch: 6, g_loss: 0.550573, d_loss: 0.545401\n",
            "epoch: 60, batch: 7, g_loss: 0.469094, d_loss: 0.582981\n",
            "epoch: 60, batch: 8, g_loss: 0.436288, d_loss: 0.573746\n",
            "epoch: 60, batch: 9, g_loss: 0.500416, d_loss: 0.590250\n",
            "epoch: 60, batch: 10, g_loss: 0.581527, d_loss: 0.601848\n",
            "epoch: 60, batch: 11, g_loss: 0.751067, d_loss: 0.626074\n",
            "epoch: 60, batch: 12, g_loss: 0.641858, d_loss: 0.572535\n",
            "epoch: 60, batch: 13, g_loss: 0.612698, d_loss: 0.581504\n",
            "epoch: 60, batch: 14, g_loss: 0.722431, d_loss: 0.542980\n",
            "epoch: 60, batch: 15, g_loss: 0.581874, d_loss: 0.637134\n",
            "epoch: 60, batch: 16, g_loss: 0.632849, d_loss: 0.640725\n",
            "epoch: 61, batch: 0, g_loss: 0.813208, d_loss: 0.542128\n",
            "epoch: 61, batch: 1, g_loss: 0.499674, d_loss: 0.459093\n",
            "epoch: 61, batch: 2, g_loss: 0.400369, d_loss: 0.480899\n",
            "epoch: 61, batch: 3, g_loss: 0.422244, d_loss: 0.633075\n",
            "epoch: 61, batch: 4, g_loss: 0.676608, d_loss: 0.595305\n",
            "epoch: 61, batch: 5, g_loss: 0.782513, d_loss: 0.569521\n",
            "epoch: 61, batch: 6, g_loss: 0.645721, d_loss: 0.528558\n",
            "epoch: 61, batch: 7, g_loss: 0.705505, d_loss: 0.649250\n",
            "epoch: 61, batch: 8, g_loss: 0.650507, d_loss: 0.590103\n",
            "epoch: 61, batch: 9, g_loss: 0.597510, d_loss: 0.591478\n",
            "epoch: 61, batch: 10, g_loss: 0.667876, d_loss: 0.592382\n",
            "epoch: 61, batch: 11, g_loss: 0.675848, d_loss: 0.642097\n",
            "epoch: 61, batch: 12, g_loss: 0.606204, d_loss: 0.588708\n",
            "epoch: 61, batch: 13, g_loss: 0.554833, d_loss: 0.554595\n",
            "epoch: 61, batch: 14, g_loss: 0.503544, d_loss: 0.563045\n",
            "epoch: 61, batch: 15, g_loss: 0.487778, d_loss: 0.533995\n",
            "epoch: 61, batch: 16, g_loss: 0.600312, d_loss: 0.637223\n",
            "epoch: 62, batch: 0, g_loss: 0.599916, d_loss: 0.611628\n",
            "epoch: 62, batch: 1, g_loss: 0.719917, d_loss: 0.559024\n",
            "epoch: 62, batch: 2, g_loss: 0.669271, d_loss: 0.600424\n",
            "epoch: 62, batch: 3, g_loss: 0.743499, d_loss: 0.549855\n",
            "epoch: 62, batch: 4, g_loss: 0.622121, d_loss: 0.624903\n",
            "epoch: 62, batch: 5, g_loss: 0.681514, d_loss: 0.617389\n",
            "epoch: 62, batch: 6, g_loss: 0.633332, d_loss: 0.549680\n",
            "epoch: 62, batch: 7, g_loss: 0.577304, d_loss: 0.474199\n",
            "epoch: 62, batch: 8, g_loss: 0.437115, d_loss: 0.492893\n",
            "epoch: 62, batch: 9, g_loss: 0.388616, d_loss: 0.562192\n",
            "epoch: 62, batch: 10, g_loss: 0.530523, d_loss: 0.612349\n",
            "epoch: 62, batch: 11, g_loss: 0.711387, d_loss: 0.549605\n",
            "epoch: 62, batch: 12, g_loss: 0.669453, d_loss: 0.588521\n",
            "epoch: 62, batch: 13, g_loss: 0.650279, d_loss: 0.606923\n",
            "epoch: 62, batch: 14, g_loss: 0.747637, d_loss: 0.573374\n",
            "epoch: 62, batch: 15, g_loss: 0.672455, d_loss: 0.557717\n",
            "epoch: 62, batch: 16, g_loss: 0.693130, d_loss: 0.555350\n",
            "epoch: 63, batch: 0, g_loss: 0.653332, d_loss: 0.701359\n",
            "epoch: 63, batch: 1, g_loss: 0.675505, d_loss: 0.570764\n",
            "epoch: 63, batch: 2, g_loss: 0.634619, d_loss: 0.581645\n",
            "epoch: 63, batch: 3, g_loss: 0.521164, d_loss: 0.630051\n",
            "epoch: 63, batch: 4, g_loss: 0.489599, d_loss: 0.584470\n",
            "epoch: 63, batch: 5, g_loss: 0.569095, d_loss: 0.543915\n",
            "epoch: 63, batch: 6, g_loss: 0.646449, d_loss: 0.583986\n",
            "epoch: 63, batch: 7, g_loss: 0.723352, d_loss: 0.574232\n",
            "epoch: 63, batch: 8, g_loss: 0.598244, d_loss: 0.605529\n",
            "epoch: 63, batch: 9, g_loss: 0.653216, d_loss: 0.657560\n",
            "epoch: 63, batch: 10, g_loss: 0.595307, d_loss: 0.620677\n",
            "epoch: 63, batch: 11, g_loss: 0.585477, d_loss: 0.573501\n",
            "epoch: 63, batch: 12, g_loss: 0.642747, d_loss: 0.591202\n",
            "epoch: 63, batch: 13, g_loss: 0.633238, d_loss: 0.573505\n",
            "epoch: 63, batch: 14, g_loss: 0.562700, d_loss: 0.594685\n",
            "epoch: 63, batch: 15, g_loss: 0.540537, d_loss: 0.554003\n",
            "epoch: 63, batch: 16, g_loss: 0.616933, d_loss: 0.588270\n",
            "epoch: 64, batch: 0, g_loss: 0.579405, d_loss: 0.598102\n",
            "epoch: 64, batch: 1, g_loss: 0.555390, d_loss: 0.604067\n",
            "epoch: 64, batch: 2, g_loss: 0.609323, d_loss: 0.575191\n",
            "epoch: 64, batch: 3, g_loss: 0.636018, d_loss: 0.610959\n",
            "epoch: 64, batch: 4, g_loss: 0.641173, d_loss: 0.610228\n",
            "epoch: 64, batch: 5, g_loss: 0.663850, d_loss: 0.616282\n",
            "epoch: 64, batch: 6, g_loss: 0.575711, d_loss: 0.583864\n",
            "epoch: 64, batch: 7, g_loss: 0.630588, d_loss: 0.615596\n",
            "epoch: 64, batch: 8, g_loss: 0.590039, d_loss: 0.605617\n",
            "epoch: 64, batch: 9, g_loss: 0.621011, d_loss: 0.628064\n",
            "epoch: 64, batch: 10, g_loss: 0.670277, d_loss: 0.604457\n",
            "epoch: 64, batch: 11, g_loss: 0.546553, d_loss: 0.606283\n",
            "epoch: 64, batch: 12, g_loss: 0.554742, d_loss: 0.597289\n",
            "epoch: 64, batch: 13, g_loss: 0.579685, d_loss: 0.552041\n",
            "epoch: 64, batch: 14, g_loss: 0.626508, d_loss: 0.534426\n",
            "epoch: 64, batch: 15, g_loss: 0.540742, d_loss: 0.615575\n",
            "epoch: 64, batch: 16, g_loss: 0.677227, d_loss: 0.679261\n",
            "epoch: 65, batch: 0, g_loss: 0.631639, d_loss: 0.644577\n",
            "epoch: 65, batch: 1, g_loss: 0.561799, d_loss: 0.565897\n",
            "epoch: 65, batch: 2, g_loss: 0.653847, d_loss: 0.556849\n",
            "epoch: 65, batch: 3, g_loss: 0.762730, d_loss: 0.615148\n",
            "epoch: 65, batch: 4, g_loss: 0.581385, d_loss: 0.585635\n",
            "epoch: 65, batch: 5, g_loss: 0.569835, d_loss: 0.552841\n",
            "epoch: 65, batch: 6, g_loss: 0.576278, d_loss: 0.524938\n",
            "epoch: 65, batch: 7, g_loss: 0.498725, d_loss: 0.529320\n",
            "epoch: 65, batch: 8, g_loss: 0.548555, d_loss: 0.595946\n",
            "epoch: 65, batch: 9, g_loss: 0.548344, d_loss: 0.645175\n",
            "epoch: 65, batch: 10, g_loss: 0.597368, d_loss: 0.602337\n",
            "epoch: 65, batch: 11, g_loss: 0.622801, d_loss: 0.558542\n",
            "epoch: 65, batch: 12, g_loss: 0.612170, d_loss: 0.598587\n",
            "epoch: 65, batch: 13, g_loss: 0.605132, d_loss: 0.601030\n",
            "epoch: 65, batch: 14, g_loss: 0.663763, d_loss: 0.581400\n",
            "epoch: 65, batch: 15, g_loss: 0.592756, d_loss: 0.558337\n",
            "epoch: 65, batch: 16, g_loss: 0.598782, d_loss: 0.646759\n",
            "epoch: 66, batch: 0, g_loss: 0.578966, d_loss: 0.585958\n",
            "epoch: 66, batch: 1, g_loss: 0.613494, d_loss: 0.537661\n",
            "epoch: 66, batch: 2, g_loss: 0.657944, d_loss: 0.568949\n",
            "epoch: 66, batch: 3, g_loss: 0.693369, d_loss: 0.583412\n",
            "epoch: 66, batch: 4, g_loss: 0.594347, d_loss: 0.614485\n",
            "epoch: 66, batch: 5, g_loss: 0.569349, d_loss: 0.615145\n",
            "epoch: 66, batch: 6, g_loss: 0.592699, d_loss: 0.628088\n",
            "epoch: 66, batch: 7, g_loss: 0.711105, d_loss: 0.572996\n",
            "epoch: 66, batch: 8, g_loss: 0.493459, d_loss: 0.566097\n",
            "epoch: 66, batch: 9, g_loss: 0.537407, d_loss: 0.581824\n",
            "epoch: 66, batch: 10, g_loss: 0.540152, d_loss: 0.549787\n",
            "epoch: 66, batch: 11, g_loss: 0.534569, d_loss: 0.666431\n",
            "epoch: 66, batch: 12, g_loss: 0.704874, d_loss: 0.604207\n",
            "epoch: 66, batch: 13, g_loss: 0.669940, d_loss: 0.538228\n",
            "epoch: 66, batch: 14, g_loss: 0.641109, d_loss: 0.525166\n",
            "epoch: 66, batch: 15, g_loss: 0.583007, d_loss: 0.509163\n",
            "epoch: 66, batch: 16, g_loss: 0.546125, d_loss: 0.543294\n",
            "epoch: 67, batch: 0, g_loss: 0.502175, d_loss: 0.625518\n",
            "epoch: 67, batch: 1, g_loss: 0.558401, d_loss: 0.577550\n",
            "epoch: 67, batch: 2, g_loss: 0.744613, d_loss: 0.549956\n",
            "epoch: 67, batch: 3, g_loss: 0.633194, d_loss: 0.600520\n",
            "epoch: 67, batch: 4, g_loss: 0.657585, d_loss: 0.608945\n",
            "epoch: 67, batch: 5, g_loss: 0.572829, d_loss: 0.544786\n",
            "epoch: 67, batch: 6, g_loss: 0.532271, d_loss: 0.586849\n",
            "epoch: 67, batch: 7, g_loss: 0.511751, d_loss: 0.598537\n",
            "epoch: 67, batch: 8, g_loss: 0.608357, d_loss: 0.571251\n",
            "epoch: 67, batch: 9, g_loss: 0.601817, d_loss: 0.554720\n",
            "epoch: 67, batch: 10, g_loss: 0.598450, d_loss: 0.562190\n",
            "epoch: 67, batch: 11, g_loss: 0.625549, d_loss: 0.546724\n",
            "epoch: 67, batch: 12, g_loss: 0.623838, d_loss: 0.567870\n",
            "epoch: 67, batch: 13, g_loss: 0.581668, d_loss: 0.607357\n",
            "epoch: 67, batch: 14, g_loss: 0.648658, d_loss: 0.614426\n",
            "epoch: 67, batch: 15, g_loss: 0.632315, d_loss: 0.570585\n",
            "epoch: 67, batch: 16, g_loss: 0.690930, d_loss: 0.595074\n",
            "epoch: 68, batch: 0, g_loss: 0.643793, d_loss: 0.604611\n",
            "epoch: 68, batch: 1, g_loss: 0.612875, d_loss: 0.583846\n",
            "epoch: 68, batch: 2, g_loss: 0.618017, d_loss: 0.560236\n",
            "epoch: 68, batch: 3, g_loss: 0.668793, d_loss: 0.643698\n",
            "epoch: 68, batch: 4, g_loss: 0.594567, d_loss: 0.591133\n",
            "epoch: 68, batch: 5, g_loss: 0.666764, d_loss: 0.540031\n",
            "epoch: 68, batch: 6, g_loss: 0.546006, d_loss: 0.640881\n",
            "epoch: 68, batch: 7, g_loss: 0.592508, d_loss: 0.620396\n",
            "epoch: 68, batch: 8, g_loss: 0.605647, d_loss: 0.578554\n",
            "epoch: 68, batch: 9, g_loss: 0.624799, d_loss: 0.574277\n",
            "epoch: 68, batch: 10, g_loss: 0.639616, d_loss: 0.557337\n",
            "epoch: 68, batch: 11, g_loss: 0.552329, d_loss: 0.578673\n",
            "epoch: 68, batch: 12, g_loss: 0.599277, d_loss: 0.572308\n",
            "epoch: 68, batch: 13, g_loss: 0.600867, d_loss: 0.571790\n",
            "epoch: 68, batch: 14, g_loss: 0.640378, d_loss: 0.549096\n",
            "epoch: 68, batch: 15, g_loss: 0.580879, d_loss: 0.573003\n",
            "epoch: 68, batch: 16, g_loss: 0.619212, d_loss: 0.553646\n",
            "epoch: 69, batch: 0, g_loss: 0.565499, d_loss: 0.605123\n",
            "epoch: 69, batch: 1, g_loss: 0.622171, d_loss: 0.631939\n",
            "epoch: 69, batch: 2, g_loss: 0.577489, d_loss: 0.539934\n",
            "epoch: 69, batch: 3, g_loss: 0.582923, d_loss: 0.624175\n",
            "epoch: 69, batch: 4, g_loss: 0.562751, d_loss: 0.550946\n",
            "epoch: 69, batch: 5, g_loss: 0.542771, d_loss: 0.614652\n",
            "epoch: 69, batch: 6, g_loss: 0.580325, d_loss: 0.598930\n",
            "epoch: 69, batch: 7, g_loss: 0.587574, d_loss: 0.597127\n",
            "epoch: 69, batch: 8, g_loss: 0.627095, d_loss: 0.615864\n",
            "epoch: 69, batch: 9, g_loss: 0.584507, d_loss: 0.626332\n",
            "epoch: 69, batch: 10, g_loss: 0.598805, d_loss: 0.588892\n",
            "epoch: 69, batch: 11, g_loss: 0.522976, d_loss: 0.602956\n",
            "epoch: 69, batch: 12, g_loss: 0.583867, d_loss: 0.604065\n",
            "epoch: 69, batch: 13, g_loss: 0.575589, d_loss: 0.561101\n",
            "epoch: 69, batch: 14, g_loss: 0.539832, d_loss: 0.528153\n",
            "epoch: 69, batch: 15, g_loss: 0.551572, d_loss: 0.593765\n",
            "epoch: 69, batch: 16, g_loss: 0.646505, d_loss: 0.564729\n",
            "epoch: 70, batch: 0, g_loss: 0.612688, d_loss: 0.570979\n",
            "epoch: 70, batch: 1, g_loss: 0.613057, d_loss: 0.585602\n",
            "epoch: 70, batch: 2, g_loss: 0.634192, d_loss: 0.612811\n",
            "epoch: 70, batch: 3, g_loss: 0.591838, d_loss: 0.585692\n",
            "epoch: 70, batch: 4, g_loss: 0.609563, d_loss: 0.609446\n",
            "epoch: 70, batch: 5, g_loss: 0.676451, d_loss: 0.592878\n",
            "epoch: 70, batch: 6, g_loss: 0.532005, d_loss: 0.559892\n",
            "epoch: 70, batch: 7, g_loss: 0.472279, d_loss: 0.537777\n",
            "epoch: 70, batch: 8, g_loss: 0.508360, d_loss: 0.572796\n",
            "epoch: 70, batch: 9, g_loss: 0.554684, d_loss: 0.563948\n",
            "epoch: 70, batch: 10, g_loss: 0.606640, d_loss: 0.596924\n",
            "epoch: 70, batch: 11, g_loss: 0.705992, d_loss: 0.562577\n",
            "epoch: 70, batch: 12, g_loss: 0.680149, d_loss: 0.608423\n",
            "epoch: 70, batch: 13, g_loss: 0.631985, d_loss: 0.601659\n",
            "epoch: 70, batch: 14, g_loss: 0.640333, d_loss: 0.542653\n",
            "epoch: 70, batch: 15, g_loss: 0.615331, d_loss: 0.550339\n",
            "epoch: 70, batch: 16, g_loss: 0.645468, d_loss: 0.579528\n",
            "epoch: 71, batch: 0, g_loss: 0.567326, d_loss: 0.616685\n",
            "epoch: 71, batch: 1, g_loss: 0.584686, d_loss: 0.559674\n",
            "epoch: 71, batch: 2, g_loss: 0.590263, d_loss: 0.546984\n",
            "epoch: 71, batch: 3, g_loss: 0.591739, d_loss: 0.589404\n",
            "epoch: 71, batch: 4, g_loss: 0.568202, d_loss: 0.598672\n",
            "epoch: 71, batch: 5, g_loss: 0.607921, d_loss: 0.559368\n",
            "epoch: 71, batch: 6, g_loss: 0.552517, d_loss: 0.550583\n",
            "epoch: 71, batch: 7, g_loss: 0.686318, d_loss: 0.609127\n",
            "epoch: 71, batch: 8, g_loss: 0.595773, d_loss: 0.575745\n",
            "epoch: 71, batch: 9, g_loss: 0.615948, d_loss: 0.631363\n",
            "epoch: 71, batch: 10, g_loss: 0.701092, d_loss: 0.595996\n",
            "epoch: 71, batch: 11, g_loss: 0.605872, d_loss: 0.643596\n",
            "epoch: 71, batch: 12, g_loss: 0.634467, d_loss: 0.536340\n",
            "epoch: 71, batch: 13, g_loss: 0.587741, d_loss: 0.551546\n",
            "epoch: 71, batch: 14, g_loss: 0.593038, d_loss: 0.618917\n",
            "epoch: 71, batch: 15, g_loss: 0.675915, d_loss: 0.548220\n",
            "epoch: 71, batch: 16, g_loss: 0.749603, d_loss: 0.525167\n",
            "epoch: 72, batch: 0, g_loss: 0.613101, d_loss: 0.617575\n",
            "epoch: 72, batch: 1, g_loss: 0.607575, d_loss: 0.602749\n",
            "epoch: 72, batch: 2, g_loss: 0.659701, d_loss: 0.574579\n",
            "epoch: 72, batch: 3, g_loss: 0.652364, d_loss: 0.620370\n",
            "epoch: 72, batch: 4, g_loss: 0.575434, d_loss: 0.569029\n",
            "epoch: 72, batch: 5, g_loss: 0.625694, d_loss: 0.590048\n",
            "epoch: 72, batch: 6, g_loss: 0.605189, d_loss: 0.541015\n",
            "epoch: 72, batch: 7, g_loss: 0.567334, d_loss: 0.567656\n",
            "epoch: 72, batch: 8, g_loss: 0.507303, d_loss: 0.545923\n",
            "epoch: 72, batch: 9, g_loss: 0.549184, d_loss: 0.580367\n",
            "epoch: 72, batch: 10, g_loss: 0.597815, d_loss: 0.544414\n",
            "epoch: 72, batch: 11, g_loss: 0.562688, d_loss: 0.594669\n",
            "epoch: 72, batch: 12, g_loss: 0.643506, d_loss: 0.552152\n",
            "epoch: 72, batch: 13, g_loss: 0.659914, d_loss: 0.582046\n",
            "epoch: 72, batch: 14, g_loss: 0.665679, d_loss: 0.544728\n",
            "epoch: 72, batch: 15, g_loss: 0.590552, d_loss: 0.534743\n",
            "epoch: 72, batch: 16, g_loss: 0.594058, d_loss: 0.591902\n",
            "epoch: 73, batch: 0, g_loss: 0.653110, d_loss: 0.680529\n",
            "epoch: 73, batch: 1, g_loss: 0.722573, d_loss: 0.603801\n",
            "epoch: 73, batch: 2, g_loss: 0.665203, d_loss: 0.563195\n",
            "epoch: 73, batch: 3, g_loss: 0.648398, d_loss: 0.554711\n",
            "epoch: 73, batch: 4, g_loss: 0.642135, d_loss: 0.590115\n",
            "epoch: 73, batch: 5, g_loss: 0.579483, d_loss: 0.594695\n",
            "epoch: 73, batch: 6, g_loss: 0.530591, d_loss: 0.559554\n",
            "epoch: 73, batch: 7, g_loss: 0.627410, d_loss: 0.628965\n",
            "epoch: 73, batch: 8, g_loss: 0.617962, d_loss: 0.590761\n",
            "epoch: 73, batch: 9, g_loss: 0.682465, d_loss: 0.577309\n",
            "epoch: 73, batch: 10, g_loss: 0.665677, d_loss: 0.566512\n",
            "epoch: 73, batch: 11, g_loss: 0.607785, d_loss: 0.583374\n",
            "epoch: 73, batch: 12, g_loss: 0.653824, d_loss: 0.551545\n",
            "epoch: 73, batch: 13, g_loss: 0.657507, d_loss: 0.525006\n",
            "epoch: 73, batch: 14, g_loss: 0.613661, d_loss: 0.545901\n",
            "epoch: 73, batch: 15, g_loss: 0.662933, d_loss: 0.584626\n",
            "epoch: 73, batch: 16, g_loss: 0.611949, d_loss: 0.591114\n",
            "epoch: 74, batch: 0, g_loss: 0.657224, d_loss: 0.615797\n",
            "epoch: 74, batch: 1, g_loss: 0.738075, d_loss: 0.579939\n",
            "epoch: 74, batch: 2, g_loss: 0.640850, d_loss: 0.560323\n",
            "epoch: 74, batch: 3, g_loss: 0.577332, d_loss: 0.615581\n",
            "epoch: 74, batch: 4, g_loss: 0.633331, d_loss: 0.545326\n",
            "epoch: 74, batch: 5, g_loss: 0.713084, d_loss: 0.542645\n",
            "epoch: 74, batch: 6, g_loss: 0.614474, d_loss: 0.521851\n",
            "epoch: 74, batch: 7, g_loss: 0.667695, d_loss: 0.598011\n",
            "epoch: 74, batch: 8, g_loss: 0.656087, d_loss: 0.603456\n",
            "epoch: 74, batch: 9, g_loss: 0.709220, d_loss: 0.598774\n",
            "epoch: 74, batch: 10, g_loss: 0.666570, d_loss: 0.489755\n",
            "epoch: 74, batch: 11, g_loss: 0.457140, d_loss: 0.515095\n",
            "epoch: 74, batch: 12, g_loss: 0.415680, d_loss: 0.557057\n",
            "epoch: 74, batch: 13, g_loss: 0.562003, d_loss: 0.576925\n",
            "epoch: 74, batch: 14, g_loss: 0.621524, d_loss: 0.600490\n",
            "epoch: 74, batch: 15, g_loss: 0.720698, d_loss: 0.533226\n",
            "epoch: 74, batch: 16, g_loss: 0.789272, d_loss: 0.555630\n",
            "epoch: 75, batch: 0, g_loss: 0.622802, d_loss: 0.536547\n",
            "epoch: 75, batch: 1, g_loss: 0.579148, d_loss: 0.537526\n",
            "epoch: 75, batch: 2, g_loss: 0.608054, d_loss: 0.601064\n",
            "epoch: 75, batch: 3, g_loss: 0.740387, d_loss: 0.567661\n",
            "epoch: 75, batch: 4, g_loss: 0.643174, d_loss: 0.646353\n",
            "epoch: 75, batch: 5, g_loss: 0.700256, d_loss: 0.553809\n",
            "epoch: 75, batch: 6, g_loss: 0.578961, d_loss: 0.512838\n",
            "epoch: 75, batch: 7, g_loss: 0.505550, d_loss: 0.537291\n",
            "epoch: 75, batch: 8, g_loss: 0.456473, d_loss: 0.584046\n",
            "epoch: 75, batch: 9, g_loss: 0.501513, d_loss: 0.575199\n",
            "epoch: 75, batch: 10, g_loss: 0.468173, d_loss: 0.567188\n",
            "epoch: 75, batch: 11, g_loss: 0.583834, d_loss: 0.617360\n",
            "epoch: 75, batch: 12, g_loss: 0.698751, d_loss: 0.541966\n",
            "epoch: 75, batch: 13, g_loss: 0.674372, d_loss: 0.571748\n",
            "epoch: 75, batch: 14, g_loss: 0.766978, d_loss: 0.513638\n",
            "epoch: 75, batch: 15, g_loss: 0.590028, d_loss: 0.480800\n",
            "epoch: 75, batch: 16, g_loss: 0.526815, d_loss: 0.509533\n",
            "epoch: 76, batch: 0, g_loss: 0.519441, d_loss: 0.668003\n",
            "epoch: 76, batch: 1, g_loss: 0.651347, d_loss: 0.617965\n",
            "epoch: 76, batch: 2, g_loss: 0.768824, d_loss: 0.486132\n",
            "epoch: 76, batch: 3, g_loss: 0.509385, d_loss: 0.564954\n",
            "epoch: 76, batch: 4, g_loss: 0.475912, d_loss: 0.540797\n",
            "epoch: 76, batch: 5, g_loss: 0.568929, d_loss: 0.532695\n",
            "epoch: 76, batch: 6, g_loss: 0.546628, d_loss: 0.497344\n",
            "epoch: 76, batch: 7, g_loss: 0.720700, d_loss: 0.556675\n",
            "epoch: 76, batch: 8, g_loss: 0.634795, d_loss: 0.574937\n",
            "epoch: 76, batch: 9, g_loss: 0.640226, d_loss: 0.645337\n",
            "epoch: 76, batch: 10, g_loss: 0.613331, d_loss: 0.602524\n",
            "epoch: 76, batch: 11, g_loss: 0.682611, d_loss: 0.555511\n",
            "epoch: 76, batch: 12, g_loss: 0.682353, d_loss: 0.564238\n",
            "epoch: 76, batch: 13, g_loss: 0.628926, d_loss: 0.577473\n",
            "epoch: 76, batch: 14, g_loss: 0.556385, d_loss: 0.578394\n",
            "epoch: 76, batch: 15, g_loss: 0.588687, d_loss: 0.533514\n",
            "epoch: 76, batch: 16, g_loss: 0.561895, d_loss: 0.543106\n",
            "epoch: 77, batch: 0, g_loss: 0.588824, d_loss: 0.595522\n",
            "epoch: 77, batch: 1, g_loss: 0.597702, d_loss: 0.553457\n",
            "epoch: 77, batch: 2, g_loss: 0.580277, d_loss: 0.508841\n",
            "epoch: 77, batch: 3, g_loss: 0.655885, d_loss: 0.541419\n",
            "epoch: 77, batch: 4, g_loss: 0.563713, d_loss: 0.556258\n",
            "epoch: 77, batch: 5, g_loss: 0.565436, d_loss: 0.552393\n",
            "epoch: 77, batch: 6, g_loss: 0.602907, d_loss: 0.534903\n",
            "epoch: 77, batch: 7, g_loss: 0.582130, d_loss: 0.531325\n",
            "epoch: 77, batch: 8, g_loss: 0.456521, d_loss: 0.522851\n",
            "epoch: 77, batch: 9, g_loss: 0.471871, d_loss: 0.532819\n",
            "epoch: 77, batch: 10, g_loss: 0.397793, d_loss: 0.472967\n",
            "epoch: 77, batch: 11, g_loss: 0.500009, d_loss: 0.584739\n",
            "epoch: 77, batch: 12, g_loss: 0.509675, d_loss: 0.464432\n",
            "epoch: 77, batch: 13, g_loss: 0.610326, d_loss: 0.530406\n",
            "epoch: 77, batch: 14, g_loss: 0.584049, d_loss: 0.582268\n",
            "epoch: 77, batch: 15, g_loss: 0.625880, d_loss: 0.559391\n",
            "epoch: 77, batch: 16, g_loss: 0.755525, d_loss: 0.647059\n",
            "epoch: 78, batch: 0, g_loss: 0.698506, d_loss: 0.519441\n",
            "epoch: 78, batch: 1, g_loss: 0.593943, d_loss: 0.522029\n",
            "epoch: 78, batch: 2, g_loss: 0.669173, d_loss: 0.444428\n",
            "epoch: 78, batch: 3, g_loss: 0.638853, d_loss: 0.405494\n",
            "epoch: 78, batch: 4, g_loss: 0.451372, d_loss: 0.532720\n",
            "epoch: 78, batch: 5, g_loss: 0.488353, d_loss: 0.574032\n",
            "epoch: 78, batch: 6, g_loss: 0.579350, d_loss: 0.635591\n",
            "epoch: 78, batch: 7, g_loss: 0.573933, d_loss: 0.561958\n",
            "epoch: 78, batch: 8, g_loss: 0.557368, d_loss: 0.618354\n",
            "epoch: 78, batch: 9, g_loss: 0.711882, d_loss: 0.625605\n",
            "epoch: 78, batch: 10, g_loss: 0.785240, d_loss: 0.588758\n",
            "epoch: 78, batch: 11, g_loss: 0.688325, d_loss: 0.590232\n",
            "epoch: 78, batch: 12, g_loss: 0.758754, d_loss: 0.547232\n",
            "epoch: 78, batch: 13, g_loss: 0.768026, d_loss: 0.425704\n",
            "epoch: 78, batch: 14, g_loss: 0.641512, d_loss: 0.431009\n",
            "epoch: 78, batch: 15, g_loss: 0.359108, d_loss: 0.376277\n",
            "epoch: 78, batch: 16, g_loss: 0.339125, d_loss: 0.467549\n",
            "epoch: 79, batch: 0, g_loss: 0.282571, d_loss: 0.451052\n",
            "epoch: 79, batch: 1, g_loss: 0.378996, d_loss: 0.482724\n",
            "epoch: 79, batch: 2, g_loss: 0.639930, d_loss: 0.509194\n",
            "epoch: 79, batch: 3, g_loss: 0.782290, d_loss: 0.527328\n",
            "epoch: 79, batch: 4, g_loss: 0.576102, d_loss: 0.544658\n",
            "epoch: 79, batch: 5, g_loss: 0.546661, d_loss: 0.544921\n",
            "epoch: 79, batch: 6, g_loss: 0.672585, d_loss: 0.595261\n",
            "epoch: 79, batch: 7, g_loss: 0.654699, d_loss: 0.581356\n",
            "epoch: 79, batch: 8, g_loss: 0.824726, d_loss: 0.579165\n",
            "epoch: 79, batch: 9, g_loss: 0.672985, d_loss: 0.532101\n",
            "epoch: 79, batch: 10, g_loss: 0.587216, d_loss: 0.561757\n",
            "epoch: 79, batch: 11, g_loss: 0.765106, d_loss: 0.560627\n",
            "epoch: 79, batch: 12, g_loss: 0.982170, d_loss: 0.463882\n",
            "epoch: 79, batch: 13, g_loss: 0.634868, d_loss: 0.497685\n",
            "epoch: 79, batch: 14, g_loss: 0.550640, d_loss: 0.461622\n",
            "epoch: 79, batch: 15, g_loss: 0.577640, d_loss: 0.474590\n",
            "epoch: 79, batch: 16, g_loss: 0.580836, d_loss: 0.582521\n",
            "epoch: 80, batch: 0, g_loss: 0.545979, d_loss: 0.601498\n",
            "epoch: 80, batch: 1, g_loss: 0.635392, d_loss: 0.573632\n",
            "epoch: 80, batch: 2, g_loss: 0.742489, d_loss: 0.520651\n",
            "epoch: 80, batch: 3, g_loss: 0.887989, d_loss: 0.585225\n",
            "epoch: 80, batch: 4, g_loss: 0.767750, d_loss: 0.552092\n",
            "epoch: 80, batch: 5, g_loss: 0.750800, d_loss: 0.579647\n",
            "epoch: 80, batch: 6, g_loss: 0.806188, d_loss: 0.527119\n",
            "epoch: 80, batch: 7, g_loss: 0.662983, d_loss: 0.561635\n",
            "epoch: 80, batch: 8, g_loss: 0.670471, d_loss: 0.590347\n",
            "epoch: 80, batch: 9, g_loss: 0.722517, d_loss: 0.655131\n",
            "epoch: 80, batch: 10, g_loss: 0.684067, d_loss: 0.552907\n",
            "epoch: 80, batch: 11, g_loss: 0.719157, d_loss: 0.546089\n",
            "epoch: 80, batch: 12, g_loss: 0.734250, d_loss: 0.556443\n",
            "epoch: 80, batch: 13, g_loss: 0.628914, d_loss: 0.550282\n",
            "epoch: 80, batch: 14, g_loss: 0.760996, d_loss: 0.598303\n",
            "epoch: 80, batch: 15, g_loss: 0.697856, d_loss: 0.551119\n",
            "epoch: 80, batch: 16, g_loss: 0.707639, d_loss: 0.550259\n",
            "epoch: 81, batch: 0, g_loss: 0.676135, d_loss: 0.550726\n",
            "epoch: 81, batch: 1, g_loss: 0.633387, d_loss: 0.597630\n",
            "epoch: 81, batch: 2, g_loss: 0.717898, d_loss: 0.548192\n",
            "epoch: 81, batch: 3, g_loss: 0.755500, d_loss: 0.627634\n",
            "epoch: 81, batch: 4, g_loss: 0.635719, d_loss: 0.551247\n",
            "epoch: 81, batch: 5, g_loss: 0.635356, d_loss: 0.562968\n",
            "epoch: 81, batch: 6, g_loss: 0.601094, d_loss: 0.564904\n",
            "epoch: 81, batch: 7, g_loss: 0.638452, d_loss: 0.604259\n",
            "epoch: 81, batch: 8, g_loss: 0.654310, d_loss: 0.586253\n",
            "epoch: 81, batch: 9, g_loss: 0.737077, d_loss: 0.589323\n",
            "epoch: 81, batch: 10, g_loss: 0.682687, d_loss: 0.484052\n",
            "epoch: 81, batch: 11, g_loss: 0.474711, d_loss: 0.554193\n",
            "epoch: 81, batch: 12, g_loss: 0.491278, d_loss: 0.551821\n",
            "epoch: 81, batch: 13, g_loss: 0.652646, d_loss: 0.563264\n",
            "epoch: 81, batch: 14, g_loss: 0.727923, d_loss: 0.559578\n",
            "epoch: 81, batch: 15, g_loss: 0.736138, d_loss: 0.517202\n",
            "epoch: 81, batch: 16, g_loss: 0.734130, d_loss: 0.532818\n",
            "epoch: 82, batch: 0, g_loss: 0.652611, d_loss: 0.585960\n",
            "epoch: 82, batch: 1, g_loss: 0.751800, d_loss: 0.606976\n",
            "epoch: 82, batch: 2, g_loss: 0.796983, d_loss: 0.520816\n",
            "epoch: 82, batch: 3, g_loss: 0.714652, d_loss: 0.515934\n",
            "epoch: 82, batch: 4, g_loss: 0.674930, d_loss: 0.598872\n",
            "epoch: 82, batch: 5, g_loss: 0.688560, d_loss: 0.537954\n",
            "epoch: 82, batch: 6, g_loss: 0.636484, d_loss: 0.557398\n",
            "epoch: 82, batch: 7, g_loss: 0.522585, d_loss: 0.561929\n",
            "epoch: 82, batch: 8, g_loss: 0.577239, d_loss: 0.601205\n",
            "epoch: 82, batch: 9, g_loss: 0.700014, d_loss: 0.586298\n",
            "epoch: 82, batch: 10, g_loss: 0.690678, d_loss: 0.558424\n",
            "epoch: 82, batch: 11, g_loss: 0.687515, d_loss: 0.602095\n",
            "epoch: 82, batch: 12, g_loss: 0.673757, d_loss: 0.551953\n",
            "epoch: 82, batch: 13, g_loss: 0.700786, d_loss: 0.587402\n",
            "epoch: 82, batch: 14, g_loss: 0.698473, d_loss: 0.551982\n",
            "epoch: 82, batch: 15, g_loss: 0.740048, d_loss: 0.564982\n",
            "epoch: 82, batch: 16, g_loss: 0.634044, d_loss: 0.587170\n",
            "epoch: 83, batch: 0, g_loss: 0.623936, d_loss: 0.572826\n",
            "epoch: 83, batch: 1, g_loss: 0.595082, d_loss: 0.563768\n",
            "epoch: 83, batch: 2, g_loss: 0.627340, d_loss: 0.537167\n",
            "epoch: 83, batch: 3, g_loss: 0.683715, d_loss: 0.538315\n",
            "epoch: 83, batch: 4, g_loss: 0.619133, d_loss: 0.560596\n",
            "epoch: 83, batch: 5, g_loss: 0.628082, d_loss: 0.540311\n",
            "epoch: 83, batch: 6, g_loss: 0.705955, d_loss: 0.527830\n",
            "epoch: 83, batch: 7, g_loss: 0.573001, d_loss: 0.505421\n",
            "epoch: 83, batch: 8, g_loss: 0.447514, d_loss: 0.537998\n",
            "epoch: 83, batch: 9, g_loss: 0.530027, d_loss: 0.610718\n",
            "epoch: 83, batch: 10, g_loss: 0.541424, d_loss: 0.521976\n",
            "epoch: 83, batch: 11, g_loss: 0.673890, d_loss: 0.532715\n",
            "epoch: 83, batch: 12, g_loss: 0.722360, d_loss: 0.537872\n",
            "epoch: 83, batch: 13, g_loss: 0.709476, d_loss: 0.515524\n",
            "epoch: 83, batch: 14, g_loss: 0.708162, d_loss: 0.498365\n",
            "epoch: 83, batch: 15, g_loss: 0.667217, d_loss: 0.460497\n",
            "epoch: 83, batch: 16, g_loss: 0.572188, d_loss: 0.492738\n",
            "epoch: 84, batch: 0, g_loss: 0.607557, d_loss: 0.610879\n",
            "epoch: 84, batch: 1, g_loss: 0.585902, d_loss: 0.528248\n",
            "epoch: 84, batch: 2, g_loss: 0.720122, d_loss: 0.527309\n",
            "epoch: 84, batch: 3, g_loss: 0.616206, d_loss: 0.521972\n",
            "epoch: 84, batch: 4, g_loss: 0.721686, d_loss: 0.599947\n",
            "epoch: 84, batch: 5, g_loss: 0.770140, d_loss: 0.520815\n",
            "epoch: 84, batch: 6, g_loss: 0.646254, d_loss: 0.539756\n",
            "epoch: 84, batch: 7, g_loss: 0.561338, d_loss: 0.551819\n",
            "epoch: 84, batch: 8, g_loss: 0.584333, d_loss: 0.539546\n",
            "epoch: 84, batch: 9, g_loss: 0.619826, d_loss: 0.567201\n",
            "epoch: 84, batch: 10, g_loss: 0.617868, d_loss: 0.572951\n",
            "epoch: 84, batch: 11, g_loss: 0.713674, d_loss: 0.497775\n",
            "epoch: 84, batch: 12, g_loss: 0.755476, d_loss: 0.551667\n",
            "epoch: 84, batch: 13, g_loss: 0.694787, d_loss: 0.569754\n",
            "epoch: 84, batch: 14, g_loss: 0.775847, d_loss: 0.557608\n",
            "epoch: 84, batch: 15, g_loss: 0.705464, d_loss: 0.516583\n",
            "epoch: 84, batch: 16, g_loss: 0.657989, d_loss: 0.520578\n",
            "epoch: 85, batch: 0, g_loss: 0.695304, d_loss: 0.531787\n",
            "epoch: 85, batch: 1, g_loss: 0.633372, d_loss: 0.586435\n",
            "epoch: 85, batch: 2, g_loss: 0.666608, d_loss: 0.537210\n",
            "epoch: 85, batch: 3, g_loss: 0.698961, d_loss: 0.545949\n",
            "epoch: 85, batch: 4, g_loss: 0.662397, d_loss: 0.599819\n",
            "epoch: 85, batch: 5, g_loss: 0.678075, d_loss: 0.527352\n",
            "epoch: 85, batch: 6, g_loss: 0.660049, d_loss: 0.516919\n",
            "epoch: 85, batch: 7, g_loss: 0.624246, d_loss: 0.517837\n",
            "epoch: 85, batch: 8, g_loss: 0.631443, d_loss: 0.514203\n",
            "epoch: 85, batch: 9, g_loss: 0.608275, d_loss: 0.584781\n",
            "epoch: 85, batch: 10, g_loss: 0.633586, d_loss: 0.573633\n",
            "epoch: 85, batch: 11, g_loss: 0.606977, d_loss: 0.524620\n",
            "epoch: 85, batch: 12, g_loss: 0.731006, d_loss: 0.521973\n",
            "epoch: 85, batch: 13, g_loss: 0.696678, d_loss: 0.514147\n",
            "epoch: 85, batch: 14, g_loss: 0.626004, d_loss: 0.547354\n",
            "epoch: 85, batch: 15, g_loss: 0.695157, d_loss: 0.548461\n",
            "epoch: 85, batch: 16, g_loss: 0.678254, d_loss: 0.528883\n",
            "epoch: 86, batch: 0, g_loss: 0.652399, d_loss: 0.516970\n",
            "epoch: 86, batch: 1, g_loss: 0.567658, d_loss: 0.521181\n",
            "epoch: 86, batch: 2, g_loss: 0.628093, d_loss: 0.489483\n",
            "epoch: 86, batch: 3, g_loss: 0.649492, d_loss: 0.578781\n",
            "epoch: 86, batch: 4, g_loss: 0.685204, d_loss: 0.508282\n",
            "epoch: 86, batch: 5, g_loss: 0.594786, d_loss: 0.532274\n",
            "epoch: 86, batch: 6, g_loss: 0.746661, d_loss: 0.571034\n",
            "epoch: 86, batch: 7, g_loss: 0.676897, d_loss: 0.572699\n",
            "epoch: 86, batch: 8, g_loss: 0.691996, d_loss: 0.587342\n",
            "epoch: 86, batch: 9, g_loss: 0.725927, d_loss: 0.553309\n",
            "epoch: 86, batch: 10, g_loss: 0.628027, d_loss: 0.565197\n",
            "epoch: 86, batch: 11, g_loss: 0.591327, d_loss: 0.583596\n",
            "epoch: 86, batch: 12, g_loss: 0.627465, d_loss: 0.586328\n",
            "epoch: 86, batch: 13, g_loss: 0.668170, d_loss: 0.512891\n",
            "epoch: 86, batch: 14, g_loss: 0.704067, d_loss: 0.538924\n",
            "epoch: 86, batch: 15, g_loss: 0.740483, d_loss: 0.498663\n",
            "epoch: 86, batch: 16, g_loss: 0.611256, d_loss: 0.523087\n",
            "epoch: 87, batch: 0, g_loss: 0.622712, d_loss: 0.577436\n",
            "epoch: 87, batch: 1, g_loss: 0.654183, d_loss: 0.550223\n",
            "epoch: 87, batch: 2, g_loss: 0.721494, d_loss: 0.541763\n",
            "epoch: 87, batch: 3, g_loss: 0.616970, d_loss: 0.550442\n",
            "epoch: 87, batch: 4, g_loss: 0.634456, d_loss: 0.539850\n",
            "epoch: 87, batch: 5, g_loss: 0.576442, d_loss: 0.536930\n",
            "epoch: 87, batch: 6, g_loss: 0.657668, d_loss: 0.555132\n",
            "epoch: 87, batch: 7, g_loss: 0.686707, d_loss: 0.556010\n",
            "epoch: 87, batch: 8, g_loss: 0.657625, d_loss: 0.583398\n",
            "epoch: 87, batch: 9, g_loss: 0.698606, d_loss: 0.590420\n",
            "epoch: 87, batch: 10, g_loss: 0.570510, d_loss: 0.543544\n",
            "epoch: 87, batch: 11, g_loss: 0.560142, d_loss: 0.525315\n",
            "epoch: 87, batch: 12, g_loss: 0.620688, d_loss: 0.553586\n",
            "epoch: 87, batch: 13, g_loss: 0.636596, d_loss: 0.516061\n",
            "epoch: 87, batch: 14, g_loss: 0.603768, d_loss: 0.508446\n",
            "epoch: 87, batch: 15, g_loss: 0.639376, d_loss: 0.468646\n",
            "epoch: 87, batch: 16, g_loss: 0.670090, d_loss: 0.532551\n",
            "epoch: 88, batch: 0, g_loss: 0.608464, d_loss: 0.555006\n",
            "epoch: 88, batch: 1, g_loss: 0.681282, d_loss: 0.559123\n",
            "epoch: 88, batch: 2, g_loss: 0.695967, d_loss: 0.526372\n",
            "epoch: 88, batch: 3, g_loss: 0.637975, d_loss: 0.608795\n",
            "epoch: 88, batch: 4, g_loss: 0.610336, d_loss: 0.554774\n",
            "epoch: 88, batch: 5, g_loss: 0.647134, d_loss: 0.533735\n",
            "epoch: 88, batch: 6, g_loss: 0.678124, d_loss: 0.556188\n",
            "epoch: 88, batch: 7, g_loss: 0.644730, d_loss: 0.520116\n",
            "epoch: 88, batch: 8, g_loss: 0.633733, d_loss: 0.495851\n",
            "epoch: 88, batch: 9, g_loss: 0.618048, d_loss: 0.544090\n",
            "epoch: 88, batch: 10, g_loss: 0.617575, d_loss: 0.545777\n",
            "epoch: 88, batch: 11, g_loss: 0.696116, d_loss: 0.554882\n",
            "epoch: 88, batch: 12, g_loss: 0.708619, d_loss: 0.516647\n",
            "epoch: 88, batch: 13, g_loss: 0.615847, d_loss: 0.504789\n",
            "epoch: 88, batch: 14, g_loss: 0.672944, d_loss: 0.522121\n",
            "epoch: 88, batch: 15, g_loss: 0.567578, d_loss: 0.520808\n",
            "epoch: 88, batch: 16, g_loss: 0.703919, d_loss: 0.619010\n",
            "epoch: 89, batch: 0, g_loss: 0.754773, d_loss: 0.538938\n",
            "epoch: 89, batch: 1, g_loss: 0.507456, d_loss: 0.455359\n",
            "epoch: 89, batch: 2, g_loss: 0.490656, d_loss: 0.453922\n",
            "epoch: 89, batch: 3, g_loss: 0.462704, d_loss: 0.509440\n",
            "epoch: 89, batch: 4, g_loss: 0.589743, d_loss: 0.554684\n",
            "epoch: 89, batch: 5, g_loss: 0.577014, d_loss: 0.524784\n",
            "epoch: 89, batch: 6, g_loss: 0.600678, d_loss: 0.506585\n",
            "epoch: 89, batch: 7, g_loss: 0.581228, d_loss: 0.525180\n",
            "epoch: 89, batch: 8, g_loss: 0.590737, d_loss: 0.534535\n",
            "epoch: 89, batch: 9, g_loss: 0.791728, d_loss: 0.605621\n",
            "epoch: 89, batch: 10, g_loss: 0.634406, d_loss: 0.542747\n",
            "epoch: 89, batch: 11, g_loss: 0.583771, d_loss: 0.494989\n",
            "epoch: 89, batch: 12, g_loss: 0.675515, d_loss: 0.500738\n",
            "epoch: 89, batch: 13, g_loss: 0.586619, d_loss: 0.583609\n",
            "epoch: 89, batch: 14, g_loss: 0.594647, d_loss: 0.544545\n",
            "epoch: 89, batch: 15, g_loss: 0.603944, d_loss: 0.506816\n",
            "epoch: 89, batch: 16, g_loss: 0.556004, d_loss: 0.528042\n",
            "epoch: 90, batch: 0, g_loss: 0.494278, d_loss: 0.488600\n",
            "epoch: 90, batch: 1, g_loss: 0.553966, d_loss: 0.502994\n",
            "epoch: 90, batch: 2, g_loss: 0.593143, d_loss: 0.473412\n",
            "epoch: 90, batch: 3, g_loss: 0.624765, d_loss: 0.511753\n",
            "epoch: 90, batch: 4, g_loss: 0.626056, d_loss: 0.526342\n",
            "epoch: 90, batch: 5, g_loss: 0.610690, d_loss: 0.504776\n",
            "epoch: 90, batch: 6, g_loss: 0.624105, d_loss: 0.543205\n",
            "epoch: 90, batch: 7, g_loss: 0.650781, d_loss: 0.569757\n",
            "epoch: 90, batch: 8, g_loss: 0.564428, d_loss: 0.544680\n",
            "epoch: 90, batch: 9, g_loss: 0.604605, d_loss: 0.541502\n",
            "epoch: 90, batch: 10, g_loss: 0.550647, d_loss: 0.510541\n",
            "epoch: 90, batch: 11, g_loss: 0.627584, d_loss: 0.584851\n",
            "epoch: 90, batch: 12, g_loss: 0.706770, d_loss: 0.510484\n",
            "epoch: 90, batch: 13, g_loss: 0.643674, d_loss: 0.509160\n",
            "epoch: 90, batch: 14, g_loss: 0.712226, d_loss: 0.604421\n",
            "epoch: 90, batch: 15, g_loss: 0.731519, d_loss: 0.544821\n",
            "epoch: 90, batch: 16, g_loss: 0.660407, d_loss: 0.522305\n",
            "epoch: 91, batch: 0, g_loss: 0.646459, d_loss: 0.525184\n",
            "epoch: 91, batch: 1, g_loss: 0.656657, d_loss: 0.564946\n",
            "epoch: 91, batch: 2, g_loss: 0.853607, d_loss: 0.494753\n",
            "epoch: 91, batch: 3, g_loss: 0.747270, d_loss: 0.500181\n",
            "epoch: 91, batch: 4, g_loss: 0.645091, d_loss: 0.585787\n",
            "epoch: 91, batch: 5, g_loss: 0.646509, d_loss: 0.545142\n",
            "epoch: 91, batch: 6, g_loss: 0.622214, d_loss: 0.511628\n",
            "epoch: 91, batch: 7, g_loss: 0.603874, d_loss: 0.541316\n",
            "epoch: 91, batch: 8, g_loss: 0.643732, d_loss: 0.547234\n",
            "epoch: 91, batch: 9, g_loss: 0.707796, d_loss: 0.551479\n",
            "epoch: 91, batch: 10, g_loss: 0.668395, d_loss: 0.527588\n",
            "epoch: 91, batch: 11, g_loss: 0.681583, d_loss: 0.530599\n",
            "epoch: 91, batch: 12, g_loss: 0.635730, d_loss: 0.495388\n",
            "epoch: 91, batch: 13, g_loss: 0.620701, d_loss: 0.512664\n",
            "epoch: 91, batch: 14, g_loss: 0.634866, d_loss: 0.527944\n",
            "epoch: 91, batch: 15, g_loss: 0.583094, d_loss: 0.474472\n",
            "epoch: 91, batch: 16, g_loss: 0.564120, d_loss: 0.544279\n",
            "epoch: 92, batch: 0, g_loss: 0.506243, d_loss: 0.521857\n",
            "epoch: 92, batch: 1, g_loss: 0.557793, d_loss: 0.505341\n",
            "epoch: 92, batch: 2, g_loss: 0.609576, d_loss: 0.498669\n",
            "epoch: 92, batch: 3, g_loss: 0.655474, d_loss: 0.598731\n",
            "epoch: 92, batch: 4, g_loss: 0.606635, d_loss: 0.515054\n",
            "epoch: 92, batch: 5, g_loss: 0.654318, d_loss: 0.561032\n",
            "epoch: 92, batch: 6, g_loss: 0.608278, d_loss: 0.535702\n",
            "epoch: 92, batch: 7, g_loss: 0.724650, d_loss: 0.571047\n",
            "epoch: 92, batch: 8, g_loss: 0.629431, d_loss: 0.586443\n",
            "epoch: 92, batch: 9, g_loss: 0.607876, d_loss: 0.533543\n",
            "epoch: 92, batch: 10, g_loss: 0.619182, d_loss: 0.470770\n",
            "epoch: 92, batch: 11, g_loss: 0.478760, d_loss: 0.503781\n",
            "epoch: 92, batch: 12, g_loss: 0.509864, d_loss: 0.490721\n",
            "epoch: 92, batch: 13, g_loss: 0.570185, d_loss: 0.487014\n",
            "epoch: 92, batch: 14, g_loss: 0.616814, d_loss: 0.487367\n",
            "epoch: 92, batch: 15, g_loss: 0.592423, d_loss: 0.469435\n",
            "epoch: 92, batch: 16, g_loss: 0.704988, d_loss: 0.480760\n",
            "epoch: 93, batch: 0, g_loss: 0.639409, d_loss: 0.536458\n",
            "epoch: 93, batch: 1, g_loss: 0.569641, d_loss: 0.491552\n",
            "epoch: 93, batch: 2, g_loss: 0.775663, d_loss: 0.520138\n",
            "epoch: 93, batch: 3, g_loss: 0.711462, d_loss: 0.487492\n",
            "epoch: 93, batch: 4, g_loss: 0.722238, d_loss: 0.645134\n",
            "epoch: 93, batch: 5, g_loss: 0.522915, d_loss: 0.445111\n",
            "epoch: 93, batch: 6, g_loss: 0.562887, d_loss: 0.517916\n",
            "epoch: 93, batch: 7, g_loss: 0.479272, d_loss: 0.466304\n",
            "epoch: 93, batch: 8, g_loss: 0.470875, d_loss: 0.505478\n",
            "epoch: 93, batch: 9, g_loss: 0.594936, d_loss: 0.463415\n",
            "epoch: 93, batch: 10, g_loss: 0.535924, d_loss: 0.476337\n",
            "epoch: 93, batch: 11, g_loss: 0.561636, d_loss: 0.448649\n",
            "epoch: 93, batch: 12, g_loss: 0.548285, d_loss: 0.510403\n",
            "epoch: 93, batch: 13, g_loss: 0.573294, d_loss: 0.473663\n",
            "epoch: 93, batch: 14, g_loss: 0.695392, d_loss: 0.463471\n",
            "epoch: 93, batch: 15, g_loss: 0.549417, d_loss: 0.472016\n",
            "epoch: 93, batch: 16, g_loss: 0.519936, d_loss: 0.473893\n",
            "epoch: 94, batch: 0, g_loss: 0.517107, d_loss: 0.524561\n",
            "epoch: 94, batch: 1, g_loss: 0.544253, d_loss: 0.507919\n",
            "epoch: 94, batch: 2, g_loss: 0.615920, d_loss: 0.446517\n",
            "epoch: 94, batch: 3, g_loss: 0.573689, d_loss: 0.494225\n",
            "epoch: 94, batch: 4, g_loss: 0.550663, d_loss: 0.517261\n",
            "epoch: 94, batch: 5, g_loss: 0.513381, d_loss: 0.455101\n",
            "epoch: 94, batch: 6, g_loss: 0.618337, d_loss: 0.473050\n",
            "epoch: 94, batch: 7, g_loss: 0.545968, d_loss: 0.484427\n",
            "epoch: 94, batch: 8, g_loss: 0.597893, d_loss: 0.526084\n",
            "epoch: 94, batch: 9, g_loss: 0.654141, d_loss: 0.521802\n",
            "epoch: 94, batch: 10, g_loss: 0.582964, d_loss: 0.512883\n",
            "epoch: 94, batch: 11, g_loss: 0.582194, d_loss: 0.503202\n",
            "epoch: 94, batch: 12, g_loss: 0.641984, d_loss: 0.493163\n",
            "epoch: 94, batch: 13, g_loss: 0.610518, d_loss: 0.485573\n",
            "epoch: 94, batch: 14, g_loss: 0.529865, d_loss: 0.470505\n",
            "epoch: 94, batch: 15, g_loss: 0.559281, d_loss: 0.471748\n",
            "epoch: 94, batch: 16, g_loss: 0.602146, d_loss: 0.512126\n",
            "epoch: 95, batch: 0, g_loss: 0.567462, d_loss: 0.512090\n",
            "epoch: 95, batch: 1, g_loss: 0.525874, d_loss: 0.461470\n",
            "epoch: 95, batch: 2, g_loss: 0.602928, d_loss: 0.483888\n",
            "epoch: 95, batch: 3, g_loss: 0.524796, d_loss: 0.508725\n",
            "epoch: 95, batch: 4, g_loss: 0.518539, d_loss: 0.467409\n",
            "epoch: 95, batch: 5, g_loss: 0.533817, d_loss: 0.418249\n",
            "epoch: 95, batch: 6, g_loss: 0.584606, d_loss: 0.507020\n",
            "epoch: 95, batch: 7, g_loss: 0.697684, d_loss: 0.506924\n",
            "epoch: 95, batch: 8, g_loss: 0.572528, d_loss: 0.486464\n",
            "epoch: 95, batch: 9, g_loss: 0.756277, d_loss: 0.602991\n",
            "epoch: 95, batch: 10, g_loss: 0.675968, d_loss: 0.524444\n",
            "epoch: 95, batch: 11, g_loss: 0.612351, d_loss: 0.473035\n",
            "epoch: 95, batch: 12, g_loss: 0.530179, d_loss: 0.468611\n",
            "epoch: 95, batch: 13, g_loss: 0.483277, d_loss: 0.430949\n",
            "epoch: 95, batch: 14, g_loss: 0.452301, d_loss: 0.443837\n",
            "epoch: 95, batch: 15, g_loss: 0.463184, d_loss: 0.400932\n",
            "epoch: 95, batch: 16, g_loss: 0.562532, d_loss: 0.472533\n",
            "epoch: 96, batch: 0, g_loss: 0.663670, d_loss: 0.451894\n",
            "epoch: 96, batch: 1, g_loss: 0.575991, d_loss: 0.524095\n",
            "epoch: 96, batch: 2, g_loss: 0.607470, d_loss: 0.469141\n",
            "epoch: 96, batch: 3, g_loss: 0.608635, d_loss: 0.478069\n",
            "epoch: 96, batch: 4, g_loss: 0.610697, d_loss: 0.566942\n",
            "epoch: 96, batch: 5, g_loss: 0.592647, d_loss: 0.473781\n",
            "epoch: 96, batch: 6, g_loss: 0.636841, d_loss: 0.499585\n",
            "epoch: 96, batch: 7, g_loss: 0.780874, d_loss: 0.540797\n",
            "epoch: 96, batch: 8, g_loss: 0.552189, d_loss: 0.508499\n",
            "epoch: 96, batch: 9, g_loss: 0.679549, d_loss: 0.549180\n",
            "epoch: 96, batch: 10, g_loss: 0.549531, d_loss: 0.509373\n",
            "epoch: 96, batch: 11, g_loss: 0.573378, d_loss: 0.481548\n",
            "epoch: 96, batch: 12, g_loss: 0.602636, d_loss: 0.540309\n",
            "epoch: 96, batch: 13, g_loss: 0.545256, d_loss: 0.459850\n",
            "epoch: 96, batch: 14, g_loss: 0.586163, d_loss: 0.491234\n",
            "epoch: 96, batch: 15, g_loss: 0.595543, d_loss: 0.500064\n",
            "epoch: 96, batch: 16, g_loss: 0.622168, d_loss: 0.564850\n",
            "epoch: 97, batch: 0, g_loss: 0.564005, d_loss: 0.469738\n",
            "epoch: 97, batch: 1, g_loss: 0.585734, d_loss: 0.467620\n",
            "epoch: 97, batch: 2, g_loss: 0.520087, d_loss: 0.483637\n",
            "epoch: 97, batch: 3, g_loss: 0.509519, d_loss: 0.465417\n",
            "epoch: 97, batch: 4, g_loss: 0.638488, d_loss: 0.496987\n",
            "epoch: 97, batch: 5, g_loss: 0.597067, d_loss: 0.440350\n",
            "epoch: 97, batch: 6, g_loss: 0.654134, d_loss: 0.495200\n",
            "epoch: 97, batch: 7, g_loss: 0.607145, d_loss: 0.460948\n",
            "epoch: 97, batch: 8, g_loss: 0.582719, d_loss: 0.522333\n",
            "epoch: 97, batch: 9, g_loss: 0.591223, d_loss: 0.541953\n",
            "epoch: 97, batch: 10, g_loss: 0.677379, d_loss: 0.535473\n",
            "epoch: 97, batch: 11, g_loss: 0.644223, d_loss: 0.511496\n",
            "epoch: 97, batch: 12, g_loss: 0.750359, d_loss: 0.587216\n",
            "epoch: 97, batch: 13, g_loss: 0.554781, d_loss: 0.471700\n",
            "epoch: 97, batch: 14, g_loss: 0.487540, d_loss: 0.428287\n",
            "epoch: 97, batch: 15, g_loss: 0.505151, d_loss: 0.463328\n",
            "epoch: 97, batch: 16, g_loss: 0.646421, d_loss: 0.469444\n",
            "epoch: 98, batch: 0, g_loss: 0.556053, d_loss: 0.442104\n",
            "epoch: 98, batch: 1, g_loss: 0.613668, d_loss: 0.447633\n",
            "epoch: 98, batch: 2, g_loss: 0.671924, d_loss: 0.512659\n",
            "epoch: 98, batch: 3, g_loss: 0.658499, d_loss: 0.495687\n",
            "epoch: 98, batch: 4, g_loss: 0.747952, d_loss: 0.519413\n",
            "epoch: 98, batch: 5, g_loss: 0.656550, d_loss: 0.485844\n",
            "epoch: 98, batch: 6, g_loss: 0.603324, d_loss: 0.493143\n",
            "epoch: 98, batch: 7, g_loss: 0.655965, d_loss: 0.524750\n",
            "epoch: 98, batch: 8, g_loss: 0.643554, d_loss: 0.518770\n",
            "epoch: 98, batch: 9, g_loss: 0.681250, d_loss: 0.551405\n",
            "epoch: 98, batch: 10, g_loss: 0.680240, d_loss: 0.477376\n",
            "epoch: 98, batch: 11, g_loss: 0.443403, d_loss: 0.487630\n",
            "epoch: 98, batch: 12, g_loss: 0.486475, d_loss: 0.495113\n",
            "epoch: 98, batch: 13, g_loss: 0.481954, d_loss: 0.444900\n",
            "epoch: 98, batch: 14, g_loss: 0.599299, d_loss: 0.468815\n",
            "epoch: 98, batch: 15, g_loss: 0.580620, d_loss: 0.490274\n",
            "epoch: 98, batch: 16, g_loss: 0.556844, d_loss: 0.465773\n",
            "epoch: 99, batch: 0, g_loss: 0.570421, d_loss: 0.509905\n",
            "epoch: 99, batch: 1, g_loss: 0.678624, d_loss: 0.562173\n",
            "epoch: 99, batch: 2, g_loss: 0.637038, d_loss: 0.450400\n",
            "epoch: 99, batch: 3, g_loss: 0.766412, d_loss: 0.479264\n",
            "epoch: 99, batch: 4, g_loss: 0.727092, d_loss: 0.487380\n",
            "epoch: 99, batch: 5, g_loss: 0.586489, d_loss: 0.504948\n",
            "epoch: 99, batch: 6, g_loss: 0.607366, d_loss: 0.510024\n",
            "epoch: 99, batch: 7, g_loss: 0.709594, d_loss: 0.514078\n",
            "epoch: 99, batch: 8, g_loss: 0.664523, d_loss: 0.515089\n",
            "epoch: 99, batch: 9, g_loss: 0.642920, d_loss: 0.520903\n",
            "epoch: 99, batch: 10, g_loss: 0.603949, d_loss: 0.501996\n",
            "epoch: 99, batch: 11, g_loss: 0.534339, d_loss: 0.447216\n",
            "epoch: 99, batch: 12, g_loss: 0.549739, d_loss: 0.460750\n",
            "epoch: 99, batch: 13, g_loss: 0.557788, d_loss: 0.472478\n",
            "epoch: 99, batch: 14, g_loss: 0.515590, d_loss: 0.410367\n",
            "epoch: 99, batch: 15, g_loss: 0.627993, d_loss: 0.490259\n",
            "epoch: 99, batch: 16, g_loss: 0.508419, d_loss: 0.521680\n",
            "epoch: 100, batch: 0, g_loss: 0.565149, d_loss: 0.556204\n",
            "epoch: 100, batch: 1, g_loss: 0.553899, d_loss: 0.561896\n",
            "epoch: 100, batch: 2, g_loss: 0.677112, d_loss: 0.487906\n",
            "epoch: 100, batch: 3, g_loss: 0.719842, d_loss: 0.505220\n",
            "epoch: 100, batch: 4, g_loss: 0.610444, d_loss: 0.545319\n",
            "epoch: 100, batch: 5, g_loss: 0.573214, d_loss: 0.622149\n",
            "epoch: 100, batch: 6, g_loss: 0.519306, d_loss: 0.463440\n",
            "epoch: 100, batch: 7, g_loss: 0.532009, d_loss: 0.398186\n",
            "epoch: 100, batch: 8, g_loss: 0.464495, d_loss: 0.497593\n",
            "epoch: 100, batch: 9, g_loss: 0.525694, d_loss: 0.446467\n",
            "epoch: 100, batch: 10, g_loss: 0.513900, d_loss: 0.466684\n",
            "epoch: 100, batch: 11, g_loss: 0.565766, d_loss: 0.514545\n",
            "epoch: 100, batch: 12, g_loss: 0.692204, d_loss: 0.496598\n",
            "epoch: 100, batch: 13, g_loss: 0.576065, d_loss: 0.513188\n",
            "epoch: 100, batch: 14, g_loss: 0.619096, d_loss: 0.512881\n",
            "epoch: 100, batch: 15, g_loss: 0.602565, d_loss: 0.428098\n",
            "epoch: 100, batch: 16, g_loss: 0.651497, d_loss: 0.520548\n",
            "epoch: 101, batch: 0, g_loss: 0.556913, d_loss: 0.468610\n",
            "epoch: 101, batch: 1, g_loss: 0.642504, d_loss: 0.529668\n",
            "epoch: 101, batch: 2, g_loss: 0.644182, d_loss: 0.479111\n",
            "epoch: 101, batch: 3, g_loss: 0.664554, d_loss: 0.533576\n",
            "epoch: 101, batch: 4, g_loss: 0.614025, d_loss: 0.518269\n",
            "epoch: 101, batch: 5, g_loss: 0.572674, d_loss: 0.488740\n",
            "epoch: 101, batch: 6, g_loss: 0.687552, d_loss: 0.534703\n",
            "epoch: 101, batch: 7, g_loss: 0.612594, d_loss: 0.495239\n",
            "epoch: 101, batch: 8, g_loss: 0.607908, d_loss: 0.461289\n",
            "epoch: 101, batch: 9, g_loss: 0.577126, d_loss: 0.494254\n",
            "epoch: 101, batch: 10, g_loss: 0.586046, d_loss: 0.514743\n",
            "epoch: 101, batch: 11, g_loss: 0.617759, d_loss: 0.581669\n",
            "epoch: 101, batch: 12, g_loss: 0.625812, d_loss: 0.548317\n",
            "epoch: 101, batch: 13, g_loss: 0.605412, d_loss: 0.507238\n",
            "epoch: 101, batch: 14, g_loss: 0.584542, d_loss: 0.445269\n",
            "epoch: 101, batch: 15, g_loss: 0.611358, d_loss: 0.495076\n",
            "epoch: 101, batch: 16, g_loss: 0.641567, d_loss: 0.492564\n",
            "epoch: 102, batch: 0, g_loss: 0.607546, d_loss: 0.495705\n",
            "epoch: 102, batch: 1, g_loss: 0.597295, d_loss: 0.484410\n",
            "epoch: 102, batch: 2, g_loss: 0.667837, d_loss: 0.467379\n",
            "epoch: 102, batch: 3, g_loss: 0.646759, d_loss: 0.559124\n",
            "epoch: 102, batch: 4, g_loss: 0.618251, d_loss: 0.586828\n",
            "epoch: 102, batch: 5, g_loss: 0.706184, d_loss: 0.469387\n",
            "epoch: 102, batch: 6, g_loss: 0.622133, d_loss: 0.477120\n",
            "epoch: 102, batch: 7, g_loss: 0.707888, d_loss: 0.512024\n",
            "epoch: 102, batch: 8, g_loss: 0.636275, d_loss: 0.473160\n",
            "epoch: 102, batch: 9, g_loss: 0.632479, d_loss: 0.538972\n",
            "epoch: 102, batch: 10, g_loss: 0.589356, d_loss: 0.473706\n",
            "epoch: 102, batch: 11, g_loss: 0.591930, d_loss: 0.463901\n",
            "epoch: 102, batch: 12, g_loss: 0.613142, d_loss: 0.507507\n",
            "epoch: 102, batch: 13, g_loss: 0.677848, d_loss: 0.501049\n",
            "epoch: 102, batch: 14, g_loss: 0.718795, d_loss: 0.474387\n",
            "epoch: 102, batch: 15, g_loss: 0.580641, d_loss: 0.465182\n",
            "epoch: 102, batch: 16, g_loss: 0.564243, d_loss: 0.482664\n",
            "epoch: 103, batch: 0, g_loss: 0.600272, d_loss: 0.530989\n",
            "epoch: 103, batch: 1, g_loss: 0.609731, d_loss: 0.495268\n",
            "epoch: 103, batch: 2, g_loss: 0.576241, d_loss: 0.462085\n",
            "epoch: 103, batch: 3, g_loss: 0.677437, d_loss: 0.451790\n",
            "epoch: 103, batch: 4, g_loss: 0.593844, d_loss: 0.505435\n",
            "epoch: 103, batch: 5, g_loss: 0.726117, d_loss: 0.535735\n",
            "epoch: 103, batch: 6, g_loss: 0.639131, d_loss: 0.512381\n",
            "epoch: 103, batch: 7, g_loss: 0.691499, d_loss: 0.497254\n",
            "epoch: 103, batch: 8, g_loss: 0.640630, d_loss: 0.506276\n",
            "epoch: 103, batch: 9, g_loss: 0.661696, d_loss: 0.575325\n",
            "epoch: 103, batch: 10, g_loss: 0.664169, d_loss: 0.490186\n",
            "epoch: 103, batch: 11, g_loss: 0.600185, d_loss: 0.495160\n",
            "epoch: 103, batch: 12, g_loss: 0.601298, d_loss: 0.469417\n",
            "epoch: 103, batch: 13, g_loss: 0.607968, d_loss: 0.429583\n",
            "epoch: 103, batch: 14, g_loss: 0.545520, d_loss: 0.469586\n",
            "epoch: 103, batch: 15, g_loss: 0.600982, d_loss: 0.414142\n",
            "epoch: 103, batch: 16, g_loss: 0.599952, d_loss: 0.441489\n",
            "epoch: 104, batch: 0, g_loss: 0.524690, d_loss: 0.455103\n",
            "epoch: 104, batch: 1, g_loss: 0.622441, d_loss: 0.493998\n",
            "epoch: 104, batch: 2, g_loss: 0.631009, d_loss: 0.432394\n",
            "epoch: 104, batch: 3, g_loss: 0.748188, d_loss: 0.472455\n",
            "epoch: 104, batch: 4, g_loss: 0.545476, d_loss: 0.496798\n",
            "epoch: 104, batch: 5, g_loss: 0.645183, d_loss: 0.446936\n",
            "epoch: 104, batch: 6, g_loss: 0.644982, d_loss: 0.464773\n",
            "epoch: 104, batch: 7, g_loss: 0.559700, d_loss: 0.473992\n",
            "epoch: 104, batch: 8, g_loss: 0.552431, d_loss: 0.492331\n",
            "epoch: 104, batch: 9, g_loss: 0.601816, d_loss: 0.464317\n",
            "epoch: 104, batch: 10, g_loss: 0.544493, d_loss: 0.468773\n",
            "epoch: 104, batch: 11, g_loss: 0.611349, d_loss: 0.483836\n",
            "epoch: 104, batch: 12, g_loss: 0.600555, d_loss: 0.480690\n",
            "epoch: 104, batch: 13, g_loss: 0.597422, d_loss: 0.467105\n",
            "epoch: 104, batch: 14, g_loss: 0.626370, d_loss: 0.467128\n",
            "epoch: 104, batch: 15, g_loss: 0.638823, d_loss: 0.473772\n",
            "epoch: 104, batch: 16, g_loss: 0.565242, d_loss: 0.469312\n",
            "epoch: 105, batch: 0, g_loss: 0.546221, d_loss: 0.466227\n",
            "epoch: 105, batch: 1, g_loss: 0.592615, d_loss: 0.476950\n",
            "epoch: 105, batch: 2, g_loss: 0.685966, d_loss: 0.426335\n",
            "epoch: 105, batch: 3, g_loss: 0.725843, d_loss: 0.482895\n",
            "epoch: 105, batch: 4, g_loss: 0.587690, d_loss: 0.472618\n",
            "epoch: 105, batch: 5, g_loss: 0.608976, d_loss: 0.441603\n",
            "epoch: 105, batch: 6, g_loss: 0.641839, d_loss: 0.428362\n",
            "epoch: 105, batch: 7, g_loss: 0.562587, d_loss: 0.446731\n",
            "epoch: 105, batch: 8, g_loss: 0.520335, d_loss: 0.453401\n",
            "epoch: 105, batch: 9, g_loss: 0.507502, d_loss: 0.501477\n",
            "epoch: 105, batch: 10, g_loss: 0.606888, d_loss: 0.466081\n",
            "epoch: 105, batch: 11, g_loss: 0.616342, d_loss: 0.536358\n",
            "epoch: 105, batch: 12, g_loss: 0.694209, d_loss: 0.429329\n",
            "epoch: 105, batch: 13, g_loss: 0.683219, d_loss: 0.511389\n",
            "epoch: 105, batch: 14, g_loss: 0.677157, d_loss: 0.530488\n",
            "epoch: 105, batch: 15, g_loss: 0.675283, d_loss: 0.491115\n",
            "epoch: 105, batch: 16, g_loss: 0.586265, d_loss: 0.493249\n",
            "epoch: 106, batch: 0, g_loss: 0.655525, d_loss: 0.467470\n",
            "epoch: 106, batch: 1, g_loss: 0.648022, d_loss: 0.502291\n",
            "epoch: 106, batch: 2, g_loss: 0.744338, d_loss: 0.432049\n",
            "epoch: 106, batch: 3, g_loss: 0.670460, d_loss: 0.482605\n",
            "epoch: 106, batch: 4, g_loss: 0.671523, d_loss: 0.470008\n",
            "epoch: 106, batch: 5, g_loss: 0.620671, d_loss: 0.460795\n",
            "epoch: 106, batch: 6, g_loss: 0.553449, d_loss: 0.463362\n",
            "epoch: 106, batch: 7, g_loss: 0.630458, d_loss: 0.511115\n",
            "epoch: 106, batch: 8, g_loss: 0.712645, d_loss: 0.472229\n",
            "epoch: 106, batch: 9, g_loss: 0.575605, d_loss: 0.532063\n",
            "epoch: 106, batch: 10, g_loss: 0.595912, d_loss: 0.510521\n",
            "epoch: 106, batch: 11, g_loss: 0.688935, d_loss: 0.514695\n",
            "epoch: 106, batch: 12, g_loss: 0.711180, d_loss: 0.534448\n",
            "epoch: 106, batch: 13, g_loss: 0.696469, d_loss: 0.544537\n",
            "epoch: 106, batch: 14, g_loss: 0.694490, d_loss: 0.492354\n",
            "epoch: 106, batch: 15, g_loss: 0.509781, d_loss: 0.422512\n",
            "epoch: 106, batch: 16, g_loss: 0.645811, d_loss: 0.500556\n",
            "epoch: 107, batch: 0, g_loss: 0.700908, d_loss: 0.477662\n",
            "epoch: 107, batch: 1, g_loss: 0.567844, d_loss: 0.508820\n",
            "epoch: 107, batch: 2, g_loss: 0.614352, d_loss: 0.462188\n",
            "epoch: 107, batch: 3, g_loss: 0.666317, d_loss: 0.463353\n",
            "epoch: 107, batch: 4, g_loss: 0.635446, d_loss: 0.480420\n",
            "epoch: 107, batch: 5, g_loss: 0.656252, d_loss: 0.474693\n",
            "epoch: 107, batch: 6, g_loss: 0.632543, d_loss: 0.432958\n",
            "epoch: 107, batch: 7, g_loss: 0.679501, d_loss: 0.463647\n",
            "epoch: 107, batch: 8, g_loss: 0.661844, d_loss: 0.482190\n",
            "epoch: 107, batch: 9, g_loss: 0.703766, d_loss: 0.527966\n",
            "epoch: 107, batch: 10, g_loss: 0.547693, d_loss: 0.413148\n",
            "epoch: 107, batch: 11, g_loss: 0.485371, d_loss: 0.477605\n",
            "epoch: 107, batch: 12, g_loss: 0.665919, d_loss: 0.463136\n",
            "epoch: 107, batch: 13, g_loss: 0.571033, d_loss: 0.495390\n",
            "epoch: 107, batch: 14, g_loss: 0.628410, d_loss: 0.475870\n",
            "epoch: 107, batch: 15, g_loss: 0.589751, d_loss: 0.444988\n",
            "epoch: 107, batch: 16, g_loss: 0.690810, d_loss: 0.494857\n",
            "epoch: 108, batch: 0, g_loss: 0.579812, d_loss: 0.448836\n",
            "epoch: 108, batch: 1, g_loss: 0.662450, d_loss: 0.495198\n",
            "epoch: 108, batch: 2, g_loss: 0.711477, d_loss: 0.464446\n",
            "epoch: 108, batch: 3, g_loss: 0.677390, d_loss: 0.438048\n",
            "epoch: 108, batch: 4, g_loss: 0.703832, d_loss: 0.605998\n",
            "epoch: 108, batch: 5, g_loss: 0.564180, d_loss: 0.459151\n",
            "epoch: 108, batch: 6, g_loss: 0.495621, d_loss: 0.483895\n",
            "epoch: 108, batch: 7, g_loss: 0.620794, d_loss: 0.540574\n",
            "epoch: 108, batch: 8, g_loss: 0.664250, d_loss: 0.486461\n",
            "epoch: 108, batch: 9, g_loss: 0.689428, d_loss: 0.549427\n",
            "epoch: 108, batch: 10, g_loss: 0.564915, d_loss: 0.512537\n",
            "epoch: 108, batch: 11, g_loss: 0.672788, d_loss: 0.480764\n",
            "epoch: 108, batch: 12, g_loss: 0.620856, d_loss: 0.490687\n",
            "epoch: 108, batch: 13, g_loss: 0.557548, d_loss: 0.533858\n",
            "epoch: 108, batch: 14, g_loss: 0.560323, d_loss: 0.464367\n",
            "epoch: 108, batch: 15, g_loss: 0.550095, d_loss: 0.384176\n",
            "epoch: 108, batch: 16, g_loss: 0.765499, d_loss: 0.451381\n",
            "epoch: 109, batch: 0, g_loss: 0.578911, d_loss: 0.575628\n",
            "epoch: 109, batch: 1, g_loss: 0.617697, d_loss: 0.461300\n",
            "epoch: 109, batch: 2, g_loss: 0.728531, d_loss: 0.499284\n",
            "epoch: 109, batch: 3, g_loss: 0.581429, d_loss: 0.487276\n",
            "epoch: 109, batch: 4, g_loss: 0.642533, d_loss: 0.476869\n",
            "epoch: 109, batch: 5, g_loss: 0.665969, d_loss: 0.470485\n",
            "epoch: 109, batch: 6, g_loss: 0.765636, d_loss: 0.489503\n",
            "epoch: 109, batch: 7, g_loss: 0.618101, d_loss: 0.502616\n",
            "epoch: 109, batch: 8, g_loss: 0.749209, d_loss: 0.538575\n",
            "epoch: 109, batch: 9, g_loss: 0.684911, d_loss: 0.519665\n",
            "epoch: 109, batch: 10, g_loss: 0.669448, d_loss: 0.476444\n",
            "epoch: 109, batch: 11, g_loss: 0.555045, d_loss: 0.491156\n",
            "epoch: 109, batch: 12, g_loss: 0.602513, d_loss: 0.487500\n",
            "epoch: 109, batch: 13, g_loss: 0.645055, d_loss: 0.465388\n",
            "epoch: 109, batch: 14, g_loss: 0.691628, d_loss: 0.500653\n",
            "epoch: 109, batch: 15, g_loss: 0.642282, d_loss: 0.493363\n",
            "epoch: 109, batch: 16, g_loss: 0.777845, d_loss: 0.486094\n",
            "epoch: 110, batch: 0, g_loss: 0.595576, d_loss: 0.506641\n",
            "epoch: 110, batch: 1, g_loss: 0.629799, d_loss: 0.539020\n",
            "epoch: 110, batch: 2, g_loss: 0.788526, d_loss: 0.455013\n",
            "epoch: 110, batch: 3, g_loss: 0.776621, d_loss: 0.427717\n",
            "epoch: 110, batch: 4, g_loss: 0.598161, d_loss: 0.466546\n",
            "epoch: 110, batch: 5, g_loss: 0.557331, d_loss: 0.456010\n",
            "epoch: 110, batch: 6, g_loss: 0.571421, d_loss: 0.456015\n",
            "epoch: 110, batch: 7, g_loss: 0.602602, d_loss: 0.470118\n",
            "epoch: 110, batch: 8, g_loss: 0.602236, d_loss: 0.476870\n",
            "epoch: 110, batch: 9, g_loss: 0.546968, d_loss: 0.482738\n",
            "epoch: 110, batch: 10, g_loss: 0.516357, d_loss: 0.481465\n",
            "epoch: 110, batch: 11, g_loss: 0.644641, d_loss: 0.407189\n",
            "epoch: 110, batch: 12, g_loss: 0.727511, d_loss: 0.461468\n",
            "epoch: 110, batch: 13, g_loss: 0.571877, d_loss: 0.466483\n",
            "epoch: 110, batch: 14, g_loss: 0.768943, d_loss: 0.506707\n",
            "epoch: 110, batch: 15, g_loss: 0.695355, d_loss: 0.446988\n",
            "epoch: 110, batch: 16, g_loss: 0.583056, d_loss: 0.434873\n",
            "epoch: 111, batch: 0, g_loss: 0.590182, d_loss: 0.473140\n",
            "epoch: 111, batch: 1, g_loss: 0.608439, d_loss: 0.453005\n",
            "epoch: 111, batch: 2, g_loss: 0.659705, d_loss: 0.467701\n",
            "epoch: 111, batch: 3, g_loss: 0.665004, d_loss: 0.499572\n",
            "epoch: 111, batch: 4, g_loss: 0.631685, d_loss: 0.499833\n",
            "epoch: 111, batch: 5, g_loss: 0.654238, d_loss: 0.448371\n",
            "epoch: 111, batch: 6, g_loss: 0.583991, d_loss: 0.457892\n",
            "epoch: 111, batch: 7, g_loss: 0.598618, d_loss: 0.421316\n",
            "epoch: 111, batch: 8, g_loss: 0.600901, d_loss: 0.464459\n",
            "epoch: 111, batch: 9, g_loss: 0.671847, d_loss: 0.543419\n",
            "epoch: 111, batch: 10, g_loss: 0.683370, d_loss: 0.462539\n",
            "epoch: 111, batch: 11, g_loss: 0.701209, d_loss: 0.488822\n",
            "epoch: 111, batch: 12, g_loss: 0.719980, d_loss: 0.497762\n",
            "epoch: 111, batch: 13, g_loss: 0.673027, d_loss: 0.511482\n",
            "epoch: 111, batch: 14, g_loss: 0.801390, d_loss: 0.444243\n",
            "epoch: 111, batch: 15, g_loss: 0.849615, d_loss: 0.474374\n",
            "epoch: 111, batch: 16, g_loss: 0.614986, d_loss: 0.479736\n",
            "epoch: 112, batch: 0, g_loss: 0.576121, d_loss: 0.502770\n",
            "epoch: 112, batch: 1, g_loss: 0.664248, d_loss: 0.439932\n",
            "epoch: 112, batch: 2, g_loss: 0.577092, d_loss: 0.377553\n",
            "epoch: 112, batch: 3, g_loss: 0.392274, d_loss: 0.437589\n",
            "epoch: 112, batch: 4, g_loss: 0.448621, d_loss: 0.419116\n",
            "epoch: 112, batch: 5, g_loss: 0.468737, d_loss: 0.463695\n",
            "epoch: 112, batch: 6, g_loss: 0.751685, d_loss: 0.423320\n",
            "epoch: 112, batch: 7, g_loss: 0.825082, d_loss: 0.499812\n",
            "epoch: 112, batch: 8, g_loss: 0.788601, d_loss: 0.494410\n",
            "epoch: 112, batch: 9, g_loss: 0.843785, d_loss: 0.491205\n",
            "epoch: 112, batch: 10, g_loss: 0.644840, d_loss: 0.563560\n",
            "epoch: 112, batch: 11, g_loss: 0.877100, d_loss: 0.551615\n",
            "epoch: 112, batch: 12, g_loss: 0.749033, d_loss: 0.507498\n",
            "epoch: 112, batch: 13, g_loss: 0.667995, d_loss: 0.421712\n",
            "epoch: 112, batch: 14, g_loss: 0.642349, d_loss: 0.465585\n",
            "epoch: 112, batch: 15, g_loss: 0.660166, d_loss: 0.451507\n",
            "epoch: 112, batch: 16, g_loss: 0.732530, d_loss: 0.426532\n",
            "epoch: 113, batch: 0, g_loss: 0.594571, d_loss: 0.495790\n",
            "epoch: 113, batch: 1, g_loss: 0.593238, d_loss: 0.474492\n",
            "epoch: 113, batch: 2, g_loss: 0.590435, d_loss: 0.441577\n",
            "epoch: 113, batch: 3, g_loss: 0.603572, d_loss: 0.480951\n",
            "epoch: 113, batch: 4, g_loss: 0.731277, d_loss: 0.464750\n",
            "epoch: 113, batch: 5, g_loss: 0.680304, d_loss: 0.493537\n",
            "epoch: 113, batch: 6, g_loss: 0.666341, d_loss: 0.446248\n",
            "epoch: 113, batch: 7, g_loss: 0.756233, d_loss: 0.474722\n",
            "epoch: 113, batch: 8, g_loss: 0.756685, d_loss: 0.469865\n",
            "epoch: 113, batch: 9, g_loss: 0.781724, d_loss: 0.556909\n",
            "epoch: 113, batch: 10, g_loss: 0.658444, d_loss: 0.487527\n",
            "epoch: 113, batch: 11, g_loss: 0.511913, d_loss: 0.494099\n",
            "epoch: 113, batch: 12, g_loss: 0.664796, d_loss: 0.464334\n",
            "epoch: 113, batch: 13, g_loss: 0.776332, d_loss: 0.477621\n",
            "epoch: 113, batch: 14, g_loss: 0.691220, d_loss: 0.413421\n",
            "epoch: 113, batch: 15, g_loss: 0.633777, d_loss: 0.385582\n",
            "epoch: 113, batch: 16, g_loss: 0.659585, d_loss: 0.500135\n",
            "epoch: 114, batch: 0, g_loss: 0.631444, d_loss: 0.517740\n",
            "epoch: 114, batch: 1, g_loss: 0.556208, d_loss: 0.442218\n",
            "epoch: 114, batch: 2, g_loss: 0.589274, d_loss: 0.438841\n",
            "epoch: 114, batch: 3, g_loss: 0.581794, d_loss: 0.469406\n",
            "epoch: 114, batch: 4, g_loss: 0.671177, d_loss: 0.437099\n",
            "epoch: 114, batch: 5, g_loss: 0.636625, d_loss: 0.509186\n",
            "epoch: 114, batch: 6, g_loss: 0.627826, d_loss: 0.452956\n",
            "epoch: 114, batch: 7, g_loss: 0.525648, d_loss: 0.489365\n",
            "epoch: 114, batch: 8, g_loss: 0.689878, d_loss: 0.484620\n",
            "epoch: 114, batch: 9, g_loss: 0.729729, d_loss: 0.529755\n",
            "epoch: 114, batch: 10, g_loss: 0.663777, d_loss: 0.486834\n",
            "epoch: 114, batch: 11, g_loss: 0.666814, d_loss: 0.488152\n",
            "epoch: 114, batch: 12, g_loss: 0.751217, d_loss: 0.518806\n",
            "epoch: 114, batch: 13, g_loss: 0.695197, d_loss: 0.443648\n",
            "epoch: 114, batch: 14, g_loss: 0.764626, d_loss: 0.448257\n",
            "epoch: 114, batch: 15, g_loss: 0.729281, d_loss: 0.466705\n",
            "epoch: 114, batch: 16, g_loss: 0.606197, d_loss: 0.434775\n",
            "epoch: 115, batch: 0, g_loss: 0.627606, d_loss: 0.576217\n",
            "epoch: 115, batch: 1, g_loss: 0.597377, d_loss: 0.487608\n",
            "epoch: 115, batch: 2, g_loss: 0.753789, d_loss: 0.477206\n",
            "epoch: 115, batch: 3, g_loss: 0.707187, d_loss: 0.481938\n",
            "epoch: 115, batch: 4, g_loss: 0.639231, d_loss: 0.522415\n",
            "epoch: 115, batch: 5, g_loss: 0.607654, d_loss: 0.450156\n",
            "epoch: 115, batch: 6, g_loss: 0.517134, d_loss: 0.434054\n",
            "epoch: 115, batch: 7, g_loss: 0.653170, d_loss: 0.457394\n",
            "epoch: 115, batch: 8, g_loss: 0.661522, d_loss: 0.466363\n",
            "epoch: 115, batch: 9, g_loss: 0.612369, d_loss: 0.523406\n",
            "epoch: 115, batch: 10, g_loss: 0.785714, d_loss: 0.590485\n",
            "epoch: 115, batch: 11, g_loss: 0.692823, d_loss: 0.431811\n",
            "epoch: 115, batch: 12, g_loss: 0.709078, d_loss: 0.510774\n",
            "epoch: 115, batch: 13, g_loss: 0.735808, d_loss: 0.454721\n",
            "epoch: 115, batch: 14, g_loss: 0.690652, d_loss: 0.443565\n",
            "epoch: 115, batch: 15, g_loss: 0.697889, d_loss: 0.439198\n",
            "epoch: 115, batch: 16, g_loss: 0.819310, d_loss: 0.517970\n",
            "epoch: 116, batch: 0, g_loss: 0.647533, d_loss: 0.477194\n",
            "epoch: 116, batch: 1, g_loss: 0.723989, d_loss: 0.465344\n",
            "epoch: 116, batch: 2, g_loss: 0.745617, d_loss: 0.450288\n",
            "epoch: 116, batch: 3, g_loss: 0.647520, d_loss: 0.424788\n",
            "epoch: 116, batch: 4, g_loss: 0.681671, d_loss: 0.476982\n",
            "epoch: 116, batch: 5, g_loss: 0.713656, d_loss: 0.480124\n",
            "epoch: 116, batch: 6, g_loss: 0.746482, d_loss: 0.454549\n",
            "epoch: 116, batch: 7, g_loss: 0.668494, d_loss: 0.456594\n",
            "epoch: 116, batch: 8, g_loss: 0.613092, d_loss: 0.513150\n",
            "epoch: 116, batch: 9, g_loss: 0.697812, d_loss: 0.551431\n",
            "epoch: 116, batch: 10, g_loss: 0.611443, d_loss: 0.518374\n",
            "epoch: 116, batch: 11, g_loss: 0.734878, d_loss: 0.488006\n",
            "epoch: 116, batch: 12, g_loss: 0.740605, d_loss: 0.446392\n",
            "epoch: 116, batch: 13, g_loss: 0.649926, d_loss: 0.526361\n",
            "epoch: 116, batch: 14, g_loss: 0.609754, d_loss: 0.366943\n",
            "epoch: 116, batch: 15, g_loss: 0.536017, d_loss: 0.376063\n",
            "epoch: 116, batch: 16, g_loss: 0.553946, d_loss: 0.519684\n",
            "epoch: 117, batch: 0, g_loss: 0.702179, d_loss: 0.462963\n",
            "epoch: 117, batch: 1, g_loss: 0.582408, d_loss: 0.461662\n",
            "epoch: 117, batch: 2, g_loss: 0.759184, d_loss: 0.508811\n",
            "epoch: 117, batch: 3, g_loss: 0.718252, d_loss: 0.453934\n",
            "epoch: 117, batch: 4, g_loss: 0.624465, d_loss: 0.496944\n",
            "epoch: 117, batch: 5, g_loss: 0.574050, d_loss: 0.408298\n",
            "epoch: 117, batch: 6, g_loss: 0.644930, d_loss: 0.458809\n",
            "epoch: 117, batch: 7, g_loss: 0.570419, d_loss: 0.431738\n",
            "epoch: 117, batch: 8, g_loss: 0.638725, d_loss: 0.496342\n",
            "epoch: 117, batch: 9, g_loss: 0.793652, d_loss: 0.506235\n",
            "epoch: 117, batch: 10, g_loss: 0.765671, d_loss: 0.549264\n",
            "epoch: 117, batch: 11, g_loss: 0.733863, d_loss: 0.419210\n",
            "epoch: 117, batch: 12, g_loss: 0.767701, d_loss: 0.488289\n",
            "epoch: 117, batch: 13, g_loss: 0.677348, d_loss: 0.472523\n",
            "epoch: 117, batch: 14, g_loss: 0.684033, d_loss: 0.424744\n",
            "epoch: 117, batch: 15, g_loss: 0.796912, d_loss: 0.538799\n",
            "epoch: 117, batch: 16, g_loss: 0.601666, d_loss: 0.437439\n",
            "epoch: 118, batch: 0, g_loss: 0.641891, d_loss: 0.463221\n",
            "epoch: 118, batch: 1, g_loss: 0.666452, d_loss: 0.432805\n",
            "epoch: 118, batch: 2, g_loss: 0.842949, d_loss: 0.410984\n",
            "epoch: 118, batch: 3, g_loss: 0.809994, d_loss: 0.404631\n",
            "epoch: 118, batch: 4, g_loss: 0.689750, d_loss: 0.598674\n",
            "epoch: 118, batch: 5, g_loss: 0.783051, d_loss: 0.487464\n",
            "epoch: 118, batch: 6, g_loss: 0.716439, d_loss: 0.471271\n",
            "epoch: 118, batch: 7, g_loss: 0.597531, d_loss: 0.498291\n",
            "epoch: 118, batch: 8, g_loss: 0.693980, d_loss: 0.520723\n",
            "epoch: 118, batch: 9, g_loss: 0.700985, d_loss: 0.518818\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}